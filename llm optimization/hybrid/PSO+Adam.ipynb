{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Implemented a hybrid optimization technique by combining Particle Swarm Optimization (PSO) and Adam to enhance model performance.**"
      ],
      "metadata": {
        "id": "0sOsZS5qbzgJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHDxHdvJZKbK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a3321e-ae9b-4f63-8a60-8e66abb897c3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/20, Best Loss: 0.28715282678604126\n",
            "Iteration 2/20, Best Loss: 0.2845440208911896\n",
            "Iteration 3/20, Best Loss: 0.2845440208911896\n",
            "Iteration 4/20, Best Loss: 0.2845440208911896\n",
            "Iteration 5/20, Best Loss: 0.2845440208911896\n",
            "Iteration 6/20, Best Loss: 0.2831883728504181\n",
            "Iteration 7/20, Best Loss: 0.2831883728504181\n",
            "Iteration 8/20, Best Loss: 0.2831883728504181\n",
            "Iteration 9/20, Best Loss: 0.2831883728504181\n",
            "Iteration 10/20, Best Loss: 0.2831883728504181\n",
            "Iteration 11/20, Best Loss: 0.2831883728504181\n",
            "Iteration 12/20, Best Loss: 0.2831883728504181\n",
            "Iteration 13/20, Best Loss: 0.2831883728504181\n",
            "Iteration 14/20, Best Loss: 0.2831883728504181\n",
            "Iteration 15/20, Best Loss: 0.2831883728504181\n",
            "Iteration 16/20, Best Loss: 0.2831883728504181\n",
            "Iteration 17/20, Best Loss: 0.2831883728504181\n",
            "Iteration 18/20, Best Loss: 0.2831883728504181\n",
            "Iteration 19/20, Best Loss: 0.2831883728504181\n",
            "Iteration 20/20, Best Loss: 0.2831883728504181\n",
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 23ms/step - accuracy: 0.7340 - loss: 0.4901 - val_accuracy: 0.8680 - val_loss: 0.2992\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9207 - loss: 0.2018 - val_accuracy: 0.8682 - val_loss: 0.3337\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9649 - loss: 0.1028 - val_accuracy: 0.8620 - val_loss: 0.3806\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9865 - loss: 0.0395 - val_accuracy: 0.8586 - val_loss: 0.5050\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9953 - loss: 0.0150 - val_accuracy: 0.8534 - val_loss: 0.9305\n",
            "Final accuracy: 0.85343998670578, Final loss: 0.9305031895637512\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load and preprocess the IMDb dataset\n",
        "max_features = 10000  # Vocabulary size\n",
        "maxlen = 200  # Max length of the review\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define the ANN architecture with 6 layers\n",
        "def create_ann(weights=None):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    if weights is not None:\n",
        "        model.set_weights(weights)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Particle Swarm Optimization (PSO)\n",
        "class Particle:\n",
        "    def __init__(self, shape):\n",
        "        self.position = [np.random.uniform(-1, 1, s) for s in shape]  # Random initial position\n",
        "        self.velocity = [np.random.uniform(-1, 1, s) for s in shape]  # Random initial velocity\n",
        "        self.best_position = self.position.copy()\n",
        "        self.best_score = float('inf')\n",
        "\n",
        "    def update_velocity(self, global_best_position, inertia=0.5, cognitive=1.5, social=1.5):\n",
        "        for i in range(len(self.velocity)):\n",
        "            inertia_comp = inertia * self.velocity[i]\n",
        "            cognitive_comp = cognitive * np.random.rand() * (self.best_position[i] - self.position[i])\n",
        "            social_comp = social * np.random.rand() * (global_best_position[i] - self.position[i])\n",
        "            self.velocity[i] = inertia_comp + cognitive_comp + social_comp\n",
        "\n",
        "    def update_position(self):\n",
        "        for i in range(len(self.position)):\n",
        "            self.position[i] += self.velocity[i]\n",
        "\n",
        "# Fitness function to evaluate the particle's position (weights)\n",
        "def fitness_function(weights):\n",
        "    model = create_ann(weights)\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=64, verbose=0)  # Quick evaluation\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return loss  # Minimize the loss\n",
        "\n",
        "# PSO algorithm\n",
        "def pso_optimization(n_particles=10, n_iterations=20):\n",
        "    shape = [w.shape for w in create_ann().get_weights()]\n",
        "    particles = [Particle(shape) for _ in range(n_particles)]\n",
        "    global_best_position = None\n",
        "    global_best_score = float('inf')\n",
        "\n",
        "    for iteration in range(n_iterations):\n",
        "        for particle in particles:\n",
        "            # Evaluate fitness\n",
        "            current_score = fitness_function(particle.position)\n",
        "\n",
        "            # Update personal best\n",
        "            if current_score < particle.best_score:\n",
        "                particle.best_score = current_score\n",
        "                particle.best_position = particle.position.copy()\n",
        "\n",
        "            # Update global best\n",
        "            if current_score < global_best_score:\n",
        "                global_best_score = current_score\n",
        "                global_best_position = particle.position.copy()\n",
        "\n",
        "        # Update velocities and positions\n",
        "        for particle in particles:\n",
        "            particle.update_velocity(global_best_position)\n",
        "            particle.update_position()\n",
        "\n",
        "        print(f\"Iteration {iteration+1}/{n_iterations}, Best Loss: {global_best_score}\")\n",
        "\n",
        "    return global_best_position\n",
        "\n",
        "# Hybrid Optimization (PSO + Adam)\n",
        "def hybrid_optimization(n_particles=10, n_pso_iterations=20, n_adam_epochs=5):\n",
        "    # 1. Run PSO to find a good set of initial weights\n",
        "    best_weights_pso = pso_optimization(n_particles=n_particles, n_iterations=n_pso_iterations)\n",
        "\n",
        "    # 2. Create the ANN model with the best PSO weights and fine-tune with Adam\n",
        "    model = create_ann(best_weights_pso)\n",
        "\n",
        "    # Fine-tune the model using Adam optimizer\n",
        "    history = model.fit(x_train, y_train, epochs=n_adam_epochs, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "    # Evaluate the final model\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    # Save accuracy and loss\n",
        "    history_data = {\n",
        "        'accuracy': history.history['val_accuracy'],\n",
        "        'loss': history.history['val_loss']\n",
        "    }\n",
        "\n",
        "    print(f\"Final accuracy: {accuracy}, Final loss: {loss}\")\n",
        "    return model, history_data\n",
        "\n",
        "# Run the hybrid optimization (PSO + Adam)\n",
        "best_model, history1 = hybrid_optimization(n_particles=10, n_pso_iterations=20, n_adam_epochs=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# Load and preprocess the IMDb dataset\n",
        "max_features = 10000  # Vocabulary size\n",
        "maxlen = 200  # Max length of the review\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define the ANN architecture with 6 layers\n",
        "def create_ann(weights=None):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "    model.add(LSTM(128, return_sequences=True))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    if weights is not None:\n",
        "        model.set_weights(weights)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Particle Swarm Optimization (PSO)\n",
        "class Particle:\n",
        "    def __init__(self, shape):\n",
        "        self.position = [np.random.uniform(-1, 1, s) for s in shape]\n",
        "        self.velocity = [np.random.uniform(-1, 1, s) for s in shape]\n",
        "        self.best_position = copy.deepcopy(self.position)\n",
        "        self.best_score = float('inf')\n",
        "\n",
        "    def update_velocity(self, global_best_position, inertia=0.5, cognitive=1.5, social=1.5):\n",
        "        for i in range(len(self.velocity)):\n",
        "            inertia_comp = inertia * self.velocity[i]\n",
        "            cognitive_comp = cognitive * np.random.rand() * (self.best_position[i] - self.position[i])\n",
        "            social_comp = social * np.random.rand() * (global_best_position[i] - self.position[i])\n",
        "            self.velocity[i] = inertia_comp + cognitive_comp + social_comp\n",
        "\n",
        "    def update_position(self):\n",
        "        for i in range(len(self.position)):\n",
        "            self.position[i] += self.velocity[i]\n",
        "\n",
        "# Genetic Algorithm functions: Selection, Crossover, Mutation\n",
        "def crossover(parent1, parent2, crossover_rate=0.5):\n",
        "    child = copy.deepcopy(parent1)\n",
        "    for i in range(len(parent1)):\n",
        "        if np.random.rand() < crossover_rate:\n",
        "            child[i] = parent2[i]\n",
        "    return child\n",
        "\n",
        "def mutate(particle, mutation_rate=0.01):\n",
        "    for i in range(len(particle)):\n",
        "        if np.random.rand() < mutation_rate:\n",
        "            particle[i] = np.random.uniform(-1, 1, particle[i].shape)\n",
        "    return particle\n",
        "\n",
        "# Fitness function for evaluation\n",
        "def fitness_function(weights):\n",
        "    model = create_ann(weights)\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=64, verbose=0)  # Fast evaluation\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return loss  # Minimize the loss\n",
        "\n",
        "# PSO Phase\n",
        "def pso_phase(n_particles=10, n_iterations=10):\n",
        "    shape = [w.shape for w in create_ann().get_weights()]\n",
        "    particles = [Particle(shape) for _ in range(n_particles)]\n",
        "    global_best_position = None\n",
        "    global_best_score = float('inf')\n",
        "\n",
        "    for iteration in range(n_iterations):\n",
        "        for particle in particles:\n",
        "            current_score = fitness_function(particle.position)\n",
        "\n",
        "            if current_score < particle.best_score:\n",
        "                particle.best_score = current_score\n",
        "                particle.best_position = copy.deepcopy(particle.position)\n",
        "\n",
        "            if current_score < global_best_score:\n",
        "                global_best_score = current_score\n",
        "                global_best_position = copy.deepcopy(particle.position)\n",
        "\n",
        "        for particle in particles:\n",
        "            particle.update_velocity(global_best_position)\n",
        "            particle.update_position()\n",
        "\n",
        "        print(f\"PSO Iteration {iteration+1}/{n_iterations}, Best Loss: {global_best_score}\")\n",
        "\n",
        "    return particles, global_best_position\n",
        "\n",
        "# Genetic Algorithm Phase\n",
        "def ga_phase(particles, n_ga_iterations=10, crossover_rate=0.7, mutation_rate=0.01):\n",
        "    for iteration in range(n_ga_iterations):\n",
        "        next_generation = []\n",
        "        for _ in range(len(particles)):\n",
        "            # Selection (choose two parents randomly)\n",
        "            parent1 = random.choice(particles).best_position\n",
        "            parent2 = random.choice(particles).best_position\n",
        "            # Crossover\n",
        "            child_position = crossover(parent1, parent2, crossover_rate)\n",
        "            # Mutation\n",
        "            mutated_position = mutate(child_position, mutation_rate)\n",
        "            # Evaluate child\n",
        "            child = Particle([w.shape for w in create_ann().get_weights()])\n",
        "            child.position = mutated_position\n",
        "            child.best_position = copy.deepcopy(mutated_position)\n",
        "            child.best_score = fitness_function(mutated_position)\n",
        "            next_generation.append(child)\n",
        "\n",
        "        particles = next_generation\n",
        "        best_particle = min(particles, key=lambda p: p.best_score)\n",
        "        print(f\"GA Iteration {iteration+1}/{n_ga_iterations}, Best Loss: {best_particle.best_score}\")\n",
        "\n",
        "    best_particle = min(particles, key=lambda p: p.best_score)\n",
        "    return best_particle.best_position\n",
        "\n",
        "# Hybrid PSO + GA Optimization\n",
        "def hybrid_optimization(n_particles=10, n_pso_iterations=10, n_ga_iterations=10):\n",
        "    # 1. PSO Phase: Find a good initial set of weights\n",
        "    particles, global_best_position = pso_phase(n_particles, n_pso_iterations)\n",
        "\n",
        "    # 2. GA Phase: Refine the solutions using Genetic Algorithm\n",
        "    best_weights_ga = ga_phase(particles, n_ga_iterations)\n",
        "\n",
        "    # 3. Final ANN Model with optimized weights from PSO + GA\n",
        "    model = create_ann(best_weights_ga)\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    # Save accuracy and loss\n",
        "    history_data = {\n",
        "        'accuracy': history.history['val_accuracy'],\n",
        "        'loss': history.history['val_loss']\n",
        "    }\n",
        "\n",
        "    print(f\"Final accuracy: {accuracy}, Final loss: {loss}\")\n",
        "    return model, history_data\n",
        "\n",
        "# Run Hybrid PSO + GA Optimization\n",
        "best_model, history2 = hybrid_optimization(n_particles=10, n_pso_iterations=10, n_ga_iterations=10)"
      ],
      "metadata": {
        "id": "FPJY0lsFZUAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956059ff-bef4-4805-b266-3410fa00e623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSO Iteration 1/10, Best Loss: 0.28545713424682617\n",
            "PSO Iteration 2/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 3/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 4/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 5/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 6/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 7/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 8/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 9/10, Best Loss: 0.2814388871192932\n",
            "PSO Iteration 10/10, Best Loss: 0.2814388871192932\n",
            "GA Iteration 1/10, Best Loss: 0.28618279099464417\n",
            "GA Iteration 2/10, Best Loss: 0.28610923886299133\n",
            "GA Iteration 3/10, Best Loss: 0.2854199707508087\n",
            "GA Iteration 4/10, Best Loss: 0.286820650100708\n",
            "GA Iteration 5/10, Best Loss: 0.28569158911705017\n",
            "GA Iteration 6/10, Best Loss: 0.28679990768432617\n",
            "GA Iteration 7/10, Best Loss: 0.2817402184009552\n",
            "GA Iteration 8/10, Best Loss: 0.2897378206253052\n",
            "GA Iteration 9/10, Best Loss: 0.28388679027557373\n",
            "GA Iteration 10/10, Best Loss: 0.2882995307445526\n",
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.7271 - loss: 0.4906 - val_accuracy: 0.8771 - val_loss: 0.2859\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.9208 - loss: 0.2075 - val_accuracy: 0.8771 - val_loss: 0.3015\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.9602 - loss: 0.1097 - val_accuracy: 0.8661 - val_loss: 0.4008\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9878 - loss: 0.0369 - val_accuracy: 0.8600 - val_loss: 0.5100\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9944 - loss: 0.0185 - val_accuracy: 0.8543 - val_loss: 0.6022\n",
            "Final accuracy: 0.8542799949645996, Final loss: 0.6021547913551331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
        "import copy\n",
        "import random\n",
        "\n",
        "# Load and preprocess the IMDb dataset\n",
        "max_features = 10000  # Vocabulary size\n",
        "maxlen = 200  # Max length of the review\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Define the ANN architecture with 6 layers\n",
        "def create_ann(weights=None):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=maxlen))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    if weights is not None:\n",
        "        model.set_weights(weights)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Particle Swarm Optimization (PSO)\n",
        "class Particle:\n",
        "    def __init__(self, shape):\n",
        "        self.position = [np.random.uniform(-1, 1, s) for s in shape]\n",
        "        self.velocity = [np.random.uniform(-1, 1, s) for s in shape]\n",
        "        self.best_position = copy.deepcopy(self.position)\n",
        "        self.best_score = float('inf')\n",
        "\n",
        "    def update_velocity(self, global_best_position, inertia=0.5, cognitive=1.5, social=1.5):\n",
        "        for i in range(len(self.velocity)):\n",
        "            inertia_comp = inertia * self.velocity[i]\n",
        "            cognitive_comp = cognitive * np.random.rand() * (self.best_position[i] - self.position[i])\n",
        "            social_comp = social * np.random.rand() * (global_best_position[i] - self.position[i])\n",
        "            self.velocity[i] = inertia_comp + cognitive_comp + social_comp\n",
        "\n",
        "    def update_position(self):\n",
        "        for i in range(len(self.position)):\n",
        "            self.position[i] += self.velocity[i]\n",
        "\n",
        "# Bat Algorithm (BA)\n",
        "class Bat:\n",
        "    def __init__(self, shape, freq_min=0, freq_max=2):\n",
        "        self.position = [np.random.uniform(-1, 1, s) for s in shape]\n",
        "        self.velocity = [np.zeros(s) for s in shape]\n",
        "        self.frequency = np.random.uniform(freq_min, freq_max)\n",
        "        self.loudness = np.random.uniform(0.5, 1)\n",
        "        self.pulse_rate = np.random.uniform(0, 1)\n",
        "        self.best_position = copy.deepcopy(self.position)\n",
        "        self.best_score = float('inf')\n",
        "\n",
        "    def update_velocity(self, global_best_position):\n",
        "        for i in range(len(self.velocity)):\n",
        "            self.velocity[i] = self.velocity[i] + self.frequency * (self.position[i] - global_best_position[i])\n",
        "\n",
        "    def update_position(self):\n",
        "        for i in range(len(self.position)):\n",
        "            self.position[i] += self.velocity[i]\n",
        "\n",
        "# Fitness function for evaluation\n",
        "def fitness_function(weights):\n",
        "    model = create_ann(weights)\n",
        "    model.fit(x_train, y_train, epochs=1, batch_size=64, verbose=0)\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "# PSO Phase\n",
        "def pso_phase(n_particles=10, n_iterations=10):\n",
        "    shape = [w.shape for w in create_ann().get_weights()]\n",
        "    particles = [Particle(shape) for _ in range(n_particles)]\n",
        "    global_best_position = None\n",
        "    global_best_score = float('inf')\n",
        "\n",
        "    for iteration in range(n_iterations):\n",
        "        for particle in particles:\n",
        "            current_score = fitness_function(particle.position)\n",
        "\n",
        "            if current_score < particle.best_score:\n",
        "                particle.best_score = current_score\n",
        "                particle.best_position = copy.deepcopy(particle.position)\n",
        "\n",
        "            if current_score < global_best_score:\n",
        "                global_best_score = current_score\n",
        "                global_best_position = copy.deepcopy(particle.position)\n",
        "\n",
        "        for particle in particles:\n",
        "            particle.update_velocity(global_best_position)\n",
        "            particle.update_position()\n",
        "\n",
        "        print(f\"PSO Iteration {iteration+1}/{n_iterations}, Best Loss: {global_best_score}\")\n",
        "\n",
        "    return particles, global_best_position\n",
        "\n",
        "# Bat Algorithm Phase\n",
        "def bat_phase(bats, global_best_position, n_bat_iterations=10, alpha=0.9, gamma=0.9):\n",
        "    shape = [w.shape for w in create_ann().get_weights()]\n",
        "\n",
        "    for iteration in range(n_bat_iterations):\n",
        "        for bat in bats:\n",
        "            bat.update_velocity(global_best_position)\n",
        "            bat.update_position()\n",
        "\n",
        "            new_position = copy.deepcopy(bat.position)\n",
        "            new_score = fitness_function(new_position)\n",
        "\n",
        "            if new_score < bat.best_score and np.random.rand() < bat.loudness:\n",
        "                bat.best_position = new_position\n",
        "                bat.best_score = new_score\n",
        "                bat.loudness *= alpha  # Reduce loudness\n",
        "                bat.pulse_rate = bat.pulse_rate * (1 - np.exp(-gamma * iteration))\n",
        "\n",
        "        best_bat = min(bats, key=lambda b: b.best_score)\n",
        "        print(f\"Bat Algorithm Iteration {iteration+1}/{n_bat_iterations}, Best Loss: {best_bat.best_score}\")\n",
        "\n",
        "    best_bat = min(bats, key=lambda b: b.best_score)\n",
        "    return best_bat.best_position\n",
        "\n",
        "# Hybrid PSO + Bat Algorithm Optimization\n",
        "def hybrid_optimization(n_particles=10, n_pso_iterations=10, n_bat_iterations=10):\n",
        "    # 1. PSO Phase: Find a good initial set of weights\n",
        "    particles, global_best_position = pso_phase(n_particles, n_pso_iterations)\n",
        "\n",
        "    # 2. Bat Algorithm Phase: Refine the solutions using Bat Algorithm\n",
        "    bats = [Bat([w.shape for w in create_ann().get_weights()]) for _ in range(n_particles)]\n",
        "    best_weights_ba = bat_phase(bats, global_best_position, n_bat_iterations)\n",
        "\n",
        "    # 3. Final ANN Model with optimized weights from PSO + Bat Algorithm\n",
        "    model = create_ann(best_weights_ba)\n",
        "\n",
        "    # Train and evaluate the model\n",
        "    history=model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test), verbose=2)\n",
        "    loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "    print(f\"Final accuracy: {accuracy}, Final loss: {loss}\")\n",
        "    return model,history\n",
        "\n",
        "# Run Hybrid PSO + Bat Algorithm Optimization\n",
        "best_model,history3 = hybrid_optimization(n_particles=10, n_pso_iterations=10, n_bat_iterations=10)"
      ],
      "metadata": {
        "id": "5JrQKksejdaY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "63d2ea48-7bb5-4d97-b4bb-db6290f2caca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b2f360ce3c46>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# Run Hybrid PSO + Bat Algorithm Optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pso_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bat_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-b2f360ce3c46>\u001b[0m in \u001b[0;36mhybrid_optimization\u001b[0;34m(n_particles, n_pso_iterations, n_bat_iterations)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhybrid_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pso_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bat_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# 1. PSO Phase: Find a good initial set of weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mparticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_best_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpso_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_particles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_pso_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# 2. Bat Algorithm Phase: Refine the solutions using Bat Algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b2f360ce3c46>\u001b[0m in \u001b[0;36mpso_phase\u001b[0;34m(n_particles, n_iterations)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparticles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mcurrent_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent_score\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mparticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-b2f360ce3c46>\u001b[0m in \u001b[0;36mfitness_function\u001b[0;34m(weights)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfitness_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_adam={\"Epoch\" : [1,2,3,4,5],\"Accuracy\" : [0.8680, 0.8682, 0.8620, 0.8586, 0.8534], \"Loss\" :[]}\n",
        "history_GA={\"Epoch\" : [1,2,3,4,5],\"Accuracy\" : [0.8771, 0.8771, 0.8661, 0.8600, 0.8543]}\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_adam[\"Epoch\"], history_adam[\"Accuracy\"], label='PSO+Adam Validation Accuracy')\n",
        "plt.plot(history_GA[\"Epoch\"], history_GA[\"Accuracy\"], label='PSO+GA Validation Accuracy')\n",
        "# Add title and labels\n",
        "plt.title('Comparison of the Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "#Display legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "1y6iyGPtb_Dq",
        "outputId": "651d30b4-c265-4a14-cb78-ca27f3462495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils import prune\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torchtext.datasets import IMDB\n",
        "\n",
        "# Load the IMDb dataset using torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Prepare data\n",
        "def yield_tokens(data_iter):\n",
        "    for _, text in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "train_iter, test_iter = IMDB(split=('train', 'test'))\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "# Convert text to tensor\n",
        "def text_pipeline(x): return vocab(tokenizer(x))\n",
        "\n",
        "def process_data(data_iter, max_len=200):\n",
        "    data, labels = [], []\n",
        "    for label, text in data_iter:\n",
        "        tokens = text_pipeline(text)[:max_len]\n",
        "        data.append(torch.tensor(tokens))\n",
        "        labels.append(1 if label == 'pos' else 0)\n",
        "\n",
        "    return pad_sequence(data, batch_first=True), torch.tensor(labels)\n",
        "\n",
        "x_train, y_train = process_data(train_iter)\n",
        "x_test, y_test = process_data(test_iter)\n",
        "\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Define the ANN architecture with 6 layers in PyTorch\n",
        "class ANNModel(nn.Module):\n",
        "    def __init__(self, vocab_size=10000, embed_size=128, max_len=200):\n",
        "        super(ANNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, 128, batch_first=True)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * max_len, 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 32)\n",
        "        self.fc4 = nn.Linear(32, 16)\n",
        "        self.output = nn.Linear(16, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = torch.relu(self.fc4(x))\n",
        "        return torch.sigmoid(self.output(x))\n",
        "\n",
        "# Particle Swarm Optimization (PSO)\n",
        "class Particle:\n",
        "    def __init__(self, shape):\n",
        "        self.position = [np.random.uniform(-1, 1, s) for s in shape]  # Random initial position\n",
        "        self.velocity = [np.random.uniform(-1, 1, s) for s in shape]  # Random initial velocity\n",
        "        self.best_position = self.position.copy()\n",
        "        self.best_score = float('inf')\n",
        "\n",
        "    def update_velocity(self, global_best_position, inertia=0.5, cognitive=1.5, social=1.5):\n",
        "        for i in range(len(self.velocity)):\n",
        "            inertia_comp = inertia * self.velocity[i]\n",
        "            cognitive_comp = cognitive * np.random.rand() * (self.best_position[i] - self.position[i])\n",
        "            social_comp = social * np.random.rand() * (global_best_position[i] - self.position[i])\n",
        "            self.velocity[i] = inertia_comp + cognitive_comp + social_comp\n",
        "\n",
        "    def update_position(self):\n",
        "        for i in range(len(self.position)):\n",
        "            self.position[i] += self.velocity[i]\n",
        "\n",
        "# Fitness function to evaluate the particle's position (weights)\n",
        "def fitness_function(model, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x.long())\n",
        "        loss = loss_fn(outputs.squeeze(), batch_y.float())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# PSO algorithm\n",
        "def pso_optimization(model, n_particles=10, n_iterations=20):\n",
        "    shape = [p.size() for p in model.parameters()]\n",
        "    particles = [Particle(shape) for _ in range(n_particles)]\n",
        "    global_best_position = None\n",
        "    global_best_score = float('inf')\n",
        "\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for iteration in range(n_iterations):\n",
        "        for particle in particles:\n",
        "            # Evaluate fitness\n",
        "            current_score = fitness_function(model, optimizer, loss_fn)\n",
        "\n",
        "            # Update personal best\n",
        "            if current_score < particle.best_score:\n",
        "                particle.best_score = current_score\n",
        "                particle.best_position = particle.position.copy()\n",
        "\n",
        "            # Update global best\n",
        "            if current_score < global_best_score:\n",
        "                global_best_score = current_score\n",
        "                global_best_position = particle.position.copy()\n",
        "\n",
        "        # Update velocities and positions\n",
        "        for particle in particles:\n",
        "            particle.update_velocity(global_best_position)\n",
        "            particle.update_position()\n",
        "\n",
        "        print(f\"Iteration {iteration+1}/{n_iterations}, Best Loss: {global_best_score}\")\n",
        "\n",
        "    return global_best_position\n",
        "\n",
        "# Accuracy calculation helper function\n",
        "def calculate_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in loader:\n",
        "            outputs = model(batch_x.long())\n",
        "            predicted = (outputs.squeeze() > 0.5).float()\n",
        "            total += batch_y.size(0)\n",
        "            correct += (predicted == batch_y.float()).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "# Hybrid Optimization (PSO + Adam) + Pruning + History\n",
        "def hybrid_optimization(model, n_particles=10, n_pso_iterations=20, n_adam_epochs=5):\n",
        "    # 1. Run PSO to find a good set of initial weights\n",
        "    best_weights_pso = pso_optimization(model, n_particles=n_particles, n_iterations=n_pso_iterations)\n",
        "\n",
        "    # 2. Fine-tune the model using Adam optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.BCELoss()\n",
        "\n",
        "    # Initialize history for loss and accuracy\n",
        "    history = {'train_loss': [], 'val_loss': [], 'val_accuracy': []}\n",
        "\n",
        "    for epoch in range(n_adam_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for batch_x, batch_y in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x.long())\n",
        "            loss = loss_fn(outputs.squeeze(), batch_y.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Average training loss for this epoch\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation loss and accuracy\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_x, batch_y in test_loader:\n",
        "                outputs = model(batch_x.long())\n",
        "                loss = loss_fn(outputs.squeeze(), batch_y.float())\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(test_loader)\n",
        "\n",
        "        val_accuracy = calculate_accuracy(model, test_loader)\n",
        "\n",
        "        # Store loss and accuracy in history\n",
        "        history['train_loss'].append(avg_train_loss)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "        print(f\"Adam Epoch {epoch+1}/{n_adam_epochs}, Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}, Val Accuracy: {val_accuracy}\")\n",
        "\n",
        "    # 3. Apply pruning to the fine-tuned model\n",
        "    parameters_to_prune = (\n",
        "        (model.fc1, 'weight'),\n",
        "        (model.fc2, 'weight'),\n",
        "        (model.fc3, 'weight'),\n",
        "    )\n",
        "\n",
        "    # Prune 20% of weights in each dense layer\n",
        "    for layer, param in parameters_to_prune:\n",
        "        prune.l1_unstructured(layer, name=param, amount=0.2)\n",
        "\n",
        "    # Remove pruning mask for deployment\n",
        "    for layer, param in parameters_to_prune:\n",
        "        prune.remove(layer, param)\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Initialize the model\n",
        "model = ANNModel(vocab_size=len(vocab), embed_size=128, max_len=200)\n",
        "\n",
        "# Run the hybrid optimization (PSO + Adam + Pruning)\n",
        "best_model, history = hybrid_optimization(model, n_particles=10, n_pso_iterations=20, n_adam_epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "3oon5KbNhIgl",
        "outputId": "d714942b-e508-4fe0-9a28-9070521cdb40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "/usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3c6ee84087de>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMDB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the IMDb dataset using torchtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# the following import has to happen first in order to load the torchtext C++ library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_extension\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m_TEXT_BUCKET\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://download.pytorch.org/models/text/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0m_init_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_init_extension\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchtext C++ Extension is not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libtorchtext\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;31m# This import is for initializing the methods registered via PyBind11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# This has to happen after the base library is loaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchtext/_extension.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m(lib)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.10/dist-packages/torchtext/lib/libtorchtext.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --force-reinstall torch\n",
        "!pip install --force-reinstall torchtext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s6jQ2On4ktEb",
        "outputId": "c916df4f-711a-475f-846c-6ad814cac085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m822.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m709.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.3\n",
            "    Uninstalling sympy-1.13.3:\n",
            "      Successfully uninstalled sympy-1.13.3\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.5\n",
            "    Uninstalling MarkupSafe-2.1.5:\n",
            "      Successfully uninstalled MarkupSafe-2.1.5\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.16.1\n",
            "    Uninstalling filelock-3.16.1:\n",
            "      Successfully uninstalled filelock-3.16.1\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.4\n",
            "    Uninstalling Jinja2-3.1.4:\n",
            "      Successfully uninstalled Jinja2-3.1.4\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.5 filelock-3.16.1 fsspec-2024.9.0 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0 typing-extensions-4.12.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "e294b91feca64b718d252439ea5b2463"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext\n",
            "  Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Collecting tqdm (from torchtext)\n",
            "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting requests (from torchtext)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting torch>=2.3.0 (from torchtext)\n",
            "  Using cached torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting numpy (from torchtext)\n",
            "  Downloading numpy-2.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock (from torch>=2.3.0->torchtext)\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch>=2.3.0->torchtext)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch>=2.3.0->torchtext)\n",
            "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch>=2.3.0->torchtext)\n",
            "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch>=2.3.0->torchtext)\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch>=2.3.0->torchtext)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch>=2.3.0->torchtext)\n",
            "  Using cached triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchtext)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchtext)\n",
            "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchtext)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchtext)\n",
            "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchtext)\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.3.0->torchtext)\n",
            "  Using cached MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=2.3.0->torchtext)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "Using cached torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl (797.1 MB)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PAzSawJ_k2Yz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
