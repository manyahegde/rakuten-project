{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a603648-4783-455e-90f0-d99a6a229fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BertForSequenceClassification' object has no attribute 'encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(texts, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Forward pass through the first two layers\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m model_part1 \u001b[38;5;241m=\u001b[39m tinybert\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mlayer[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Get the initial hidden states from the embedding layer\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m tinybert\u001b[38;5;241m.\u001b[39membeddings(inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1729\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'encoder'"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AutoTokenizer, AutoModel \n",
    "import pickle\n",
    "\n",
    "# Load TinyBERT model and tokenizer\n",
    "tinybert = BertForSequenceClassification.from_pretrained(\"./optimized_tinybert\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./optimized_tinybert\")\n",
    "# Example input texts (batch)\n",
    "texts = [\n",
    "    \"I love this product!\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"The service was fantastic!\",\n",
    "    \"Not worth the price.\",\n",
    "    \"I would recommend this!\"\n",
    "]\n",
    "\n",
    "# Tokenize the input texts\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Forward pass through the first two layers\n",
    "model_part1 = tinybert.encoder.layer[:2]\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get the initial hidden states from the embedding layer\n",
    "    hidden_states = tinybert.embeddings(inputs['input_ids'])\n",
    "    \n",
    "    # Pass through the first two layers\n",
    "    for layer in model_part1:\n",
    "        hidden_states = layer(hidden_states)[0]  # Get the output from each layer\n",
    "\n",
    "# Serialize and send the intermediate tensor to the server\n",
    "data = pickle.dumps(hidden_states)\n",
    "client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "client_socket.connect(('172.16.19.59', 10300))  # Adjust host and port as needed\n",
    "client_socket.sendall(data)\n",
    "client_socket.close()\n",
    "print(\"Intermediate output sent to server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6462e56-be02-46bf-920c-29d7698e15b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate output sent to server.\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import pickle\n",
    "\n",
    "# Load TinyBERT model and tokenizer from local files\n",
    "tinybert = BertForSequenceClassification.from_pretrained(\"./optimized_tinybert\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./optimized_tinybert\")\n",
    "\n",
    "# Example input texts (batch)\n",
    "texts = [\n",
    "    \"I love this product!\",\n",
    "    \"This is the worst experience I've ever had.\",\n",
    "    \"The service was fantastic!\",\n",
    "    \"Not worth the price.\",\n",
    "    \"I would recommend this!\"\n",
    "]\n",
    "\n",
    "# Tokenize the input texts\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Forward pass through the first two layers\n",
    "model_part1 = tinybert.bert.encoder.layer[:2]  # Access the encoder correctly\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Get the initial hidden states from the embedding layer\n",
    "    hidden_states = tinybert.bert.embeddings(inputs['input_ids'])\n",
    "    \n",
    "    # Pass through the first two layers\n",
    "    for layer in model_part1:\n",
    "        hidden_states = layer(hidden_states)[0]  # Get the output from each layer\n",
    "\n",
    "# Serialize and send the intermediate tensor to the server\n",
    "data = pickle.dumps(hidden_states)\n",
    "\n",
    "try:\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    client_socket.connect(('172.16.19.59', 10300))  # Adjust host and port as needed\n",
    "    client_socket.sendall(data)\n",
    "except Exception as e:\n",
    "    print(f\"Error sending data: {e}\")\n",
    "finally:\n",
    "    client_socket.close()\n",
    "\n",
    "print(\"Intermediate output sent to server.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7be6dec-b3d0-465c-a43f-2e2f1d94ea10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-1): 2 x BertLayer(\n",
       "    (attention): BertAttention(\n",
       "      (self): BertSdpaSelfAttention(\n",
       "        (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "        (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "        (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (output): BertSelfOutput(\n",
       "        (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "        (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (intermediate): BertIntermediate(\n",
       "      (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
       "      (intermediate_act_fn): GELUActivation()\n",
       "    )\n",
       "    (output): BertOutput(\n",
       "      (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "981d9368-dcd1-4449-aaca-0922020bd1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.00%\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import pickle\n",
    "\n",
    "# Load TinyBERT model and tokenizer from local files\n",
    "tinybert = BertForSequenceClassification.from_pretrained(\"./optimized_tinybert\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./optimized_tinybert\")\n",
    "\n",
    "# Example input texts (batch)\n",
    "texts = [\n",
    "    \"I love this product!\",               # Expected label: 1\n",
    "    \"This is the worst experience I've ever had.\",  # Expected label: 0\n",
    "    \"The service was fantastic!\",         # Expected label: 1\n",
    "    \"Not worth the price.\",               # Expected label: 0\n",
    "    \"I would recommend this!\"             # Expected label: 1\n",
    "]\n",
    "\n",
    "# Example true labels (adjust these based on your actual labels)\n",
    "true_labels = torch.tensor([1, 0, 1, 0, 1])  # Replace with actual labels\n",
    "\n",
    "# Tokenize the input texts\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = tinybert(**inputs)  # Forward pass\n",
    "    logits = outputs.logits  # Get the logits\n",
    "    predictions = torch.argmax(logits, dim=-1)  # Get the predicted classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (predictions == true_labels).float().mean().item()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3640d8-6982-4309-afe5-50ea6a6a36b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load TinyBERT model and tokenizer from local files\n",
    "tinybert = BertForSequenceClassification.from_pretrained(\"./optimized_tinybert\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./optimized_tinybert\")\n",
    "\n",
    "# Load the IMDb dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# Use the test set\n",
    "test_texts = dataset['test']['text']\n",
    "test_labels = torch.tensor(dataset['test']['label'])\n",
    "\n",
    "# Tokenize the input texts\n",
    "inputs = tokenizer(test_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = tinybert(**inputs)  # Forward pass\n",
    "    logits = outputs.logits  # Get the logits\n",
    "    predictions = torch.argmax(logits, dim=-1)  # Get the predicted classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (predictions == test_labels).float().mean().item()\n",
    "print(f\"Accuracy on IMDb test set: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adcd059d-8cae-4168-8e25-e375c014a363",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hi\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hi' is not defined"
     ]
    }
   ],
   "source": [
    "hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a57a2e1-9861-4430-9d38-27a2dddb175b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ji'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ji\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1334dc66-56af-47b0-b4c2-5a745b6eefc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import pickle\n",
    "\n",
    "# Load TinyBERT model and tokenizer from local files\n",
    "tinybert = BertForSequenceClassification.from_pretrained(\"./optimized_tinybert\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./optimized_tinybert\")\n",
    "\n",
    "# IMDb test reviews and their expected labels\n",
    "texts = [\n",
    "    \"I loved this movie! It was fantastic and well-made.\",      # Expected label: 1\n",
    "    \"This was the worst film I have ever seen. Very disappointing.\",  # Expected label: 0\n",
    "    \"An absolute masterpiece. The performances were outstanding.\",  # Expected label: 1\n",
    "    \"I wouldn't recommend this to anyone. It's a waste of time.\",  # Expected label: 0\n",
    "    \"Great storyline and excellent direction. A must-watch!\",      # Expected label: 1\n",
    "    \"Terrible acting and a boring plot. I regret watching it.\"     # Expected label: 0\n",
    "]\n",
    "\n",
    "# Corresponding true labels for the reviews\n",
    "true_labels = torch.tensor([1, 0, 1, 0, 1, 0])  # Replace with actual labels\n",
    "\n",
    "# Tokenize the input texts\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = tinybert(**inputs)  # Forward pass\n",
    "    logits = outputs.logits  # Get the logits\n",
    "    predictions = torch.argmax(logits, dim=-1)  # Get the predicted classes\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = (predictions == true_labels).float().mean().item()\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7da230-be74-4748-b993-b600dda78ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
