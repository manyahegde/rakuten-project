{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7b5e256-4087-4200-972f-654920af0041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/bert_uncased_L-2_H-128_A-2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to server at 172.16.19.7:1700\n",
      "Processed batch output: tensor([[[0.1730, 0.1164],\n",
      "         [0.1552, 0.1834],\n",
      "         [0.1654, 0.0787],\n",
      "         ...,\n",
      "         [0.2110, 0.0769],\n",
      "         [0.2143, 0.1423],\n",
      "         [0.2415, 0.1590]],\n",
      "\n",
      "        [[0.1667, 0.1133],\n",
      "         [0.1629, 0.1646],\n",
      "         [0.1853, 0.0999],\n",
      "         ...,\n",
      "         [0.1970, 0.0999],\n",
      "         [0.2118, 0.1301],\n",
      "         [0.2541, 0.1112]],\n",
      "\n",
      "        [[0.1493, 0.1432],\n",
      "         [0.1572, 0.1869],\n",
      "         [0.1605, 0.1101],\n",
      "         ...,\n",
      "         [0.2060, 0.0952],\n",
      "         [0.2615, 0.1272],\n",
      "         [0.2759, 0.1140]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.1816, 0.1370],\n",
      "         [0.1469, 0.1482],\n",
      "         [0.1722, 0.1022],\n",
      "         ...,\n",
      "         [0.2328, 0.0584],\n",
      "         [0.2274, 0.0941],\n",
      "         [0.2760, 0.1180]],\n",
      "\n",
      "        [[0.1471, 0.1492],\n",
      "         [0.1530, 0.1503],\n",
      "         [0.1726, 0.1045],\n",
      "         ...,\n",
      "         [0.1844, 0.1206],\n",
      "         [0.1975, 0.1624],\n",
      "         [0.2444, 0.1139]],\n",
      "\n",
      "        [[0.1784, 0.1285],\n",
      "         [0.1421, 0.1832],\n",
      "         [0.1715, 0.0868],\n",
      "         ...,\n",
      "         [0.2285, 0.1004],\n",
      "         [0.2562, 0.1086],\n",
      "         [0.2752, 0.1108]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "import pickle\n",
    "\n",
    "# Set up the client to connect to the server\n",
    "def start_client(server_host='172.16.19.7', server_port=1700):\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    client_socket.connect((server_host, server_port))\n",
    "    print(f\"Connected to server at {server_host}:{server_port}\")\n",
    "\n",
    "    return client_socket\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"google/bert_uncased_L-2_H-128_A-2\", num_labels=2)\n",
    "\n",
    "# Manually split the model: Second part of the model (classifier head)\n",
    "class BertPart2(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(BertPart2, self).__init__()\n",
    "        self.classifier = model.classifier  # Extract the classifier part of the model\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        return self.classifier(hidden_states)  # Pass the hidden states through the classifier\n",
    "\n",
    "# Create the second part of the model\n",
    "model_part2 = BertPart2(model)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_part2.to(device)\n",
    "\n",
    "# Start the client and connect to the server\n",
    "client_socket = start_client(server_host='172.16.19.7', server_port=1700)  # Change to your server's IP if needed\n",
    "\n",
    "# Continuously receive batches from the server and process\n",
    "while True:\n",
    "    try:\n",
    "        # Receive data from the server\n",
    "        received_data = b''\n",
    "        while True:\n",
    "            chunk = client_socket.recv(4096)\n",
    "            if not chunk:\n",
    "                break\n",
    "            received_data += chunk\n",
    "\n",
    "        if not received_data:\n",
    "            break  # Break if no more data is received\n",
    "\n",
    "        # Deserialize the received data\n",
    "        hidden_states = pickle.loads(received_data)\n",
    "\n",
    "        # Convert the received data to a torch tensor and move to device\n",
    "        hidden_states = torch.tensor(hidden_states).to(device)\n",
    "\n",
    "        # Forward pass through the second part of the model\n",
    "        outputs = model_part2(hidden_states)\n",
    "\n",
    "        # Perform any additional steps, like loss computation or inference\n",
    "        print(f\"Processed batch output: {outputs}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "        break\n",
    "\n",
    "# Close the connection when done\n",
    "client_socket.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7ded17-46ed-4697-9d77-531a238a4ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1730,  0.1164],\n",
       "        [ 0.1552,  0.1834],\n",
       "        [ 0.1654,  0.0787],\n",
       "        [ 0.1800, -0.0280],\n",
       "        [ 0.1743, -0.0449],\n",
       "        [ 0.1943, -0.0607],\n",
       "        [ 0.1695, -0.0091],\n",
       "        [ 0.1854,  0.0215],\n",
       "        [ 0.2449,  0.0053],\n",
       "        [ 0.2659, -0.0124],\n",
       "        [ 0.2998, -0.0553],\n",
       "        [ 0.3253,  0.0160],\n",
       "        [ 0.3075,  0.0604],\n",
       "        [ 0.2925,  0.1245],\n",
       "        [ 0.2925,  0.1520],\n",
       "        [ 0.2817,  0.1395],\n",
       "        [ 0.2883,  0.0852],\n",
       "        [ 0.2660,  0.0466],\n",
       "        [ 0.2556,  0.0212],\n",
       "        [ 0.2487,  0.0496],\n",
       "        [ 0.2228,  0.1331],\n",
       "        [ 0.1691,  0.1274],\n",
       "        [ 0.1829,  0.1120],\n",
       "        [ 0.2244,  0.1050],\n",
       "        [ 0.3061,  0.1180],\n",
       "        [ 0.3351,  0.0746],\n",
       "        [ 0.3608,  0.0763],\n",
       "        [ 0.3816,  0.0860],\n",
       "        [ 0.3670,  0.1395],\n",
       "        [ 0.3309,  0.2108],\n",
       "        [ 0.3272,  0.2167],\n",
       "        [ 0.3063,  0.1720],\n",
       "        [ 0.2855,  0.1556],\n",
       "        [ 0.2654,  0.0438],\n",
       "        [ 0.2440,  0.0228],\n",
       "        [ 0.2299,  0.0279],\n",
       "        [ 0.2191,  0.0788],\n",
       "        [ 0.1959,  0.1344],\n",
       "        [ 0.2214,  0.1599],\n",
       "        [ 0.2706,  0.1303],\n",
       "        [ 0.3119,  0.0723],\n",
       "        [ 0.3229,  0.0403],\n",
       "        [ 0.3298,  0.0637],\n",
       "        [ 0.2958,  0.0843],\n",
       "        [ 0.2375,  0.1501],\n",
       "        [ 0.1988,  0.1602],\n",
       "        [ 0.1651,  0.2109],\n",
       "        [ 0.1570,  0.1143],\n",
       "        [ 0.1659,  0.0609],\n",
       "        [ 0.1926,  0.0155],\n",
       "        [ 0.2038,  0.0470],\n",
       "        [ 0.2100,  0.0673],\n",
       "        [ 0.2124,  0.0744],\n",
       "        [ 0.2353,  0.1079],\n",
       "        [ 0.2966,  0.0829],\n",
       "        [ 0.3394,  0.0374],\n",
       "        [ 0.3891,  0.0219],\n",
       "        [ 0.3412,  0.0203],\n",
       "        [ 0.3531,  0.1108],\n",
       "        [ 0.3235,  0.1681],\n",
       "        [ 0.3217,  0.1730],\n",
       "        [ 0.3300,  0.1524],\n",
       "        [ 0.3172,  0.0923],\n",
       "        [ 0.3023,  0.0241],\n",
       "        [ 0.2936,  0.0690],\n",
       "        [ 0.2532,  0.0833],\n",
       "        [ 0.2131,  0.0987],\n",
       "        [ 0.1909,  0.0637],\n",
       "        [ 0.2519,  0.0369],\n",
       "        [ 0.3270,  0.0417],\n",
       "        [ 0.3401,  0.0461],\n",
       "        [ 0.3558,  0.0043],\n",
       "        [ 0.3771, -0.0188],\n",
       "        [ 0.3692,  0.0186],\n",
       "        [ 0.3604,  0.0780],\n",
       "        [ 0.3235,  0.0806],\n",
       "        [ 0.3003,  0.0904],\n",
       "        [ 0.2682,  0.0858],\n",
       "        [ 0.2779,  0.0306],\n",
       "        [ 0.2560,  0.0085],\n",
       "        [ 0.2442, -0.0591],\n",
       "        [ 0.2336, -0.0533],\n",
       "        [ 0.1992,  0.0094],\n",
       "        [ 0.1674,  0.0100],\n",
       "        [ 0.1501,  0.0451],\n",
       "        [ 0.1684, -0.0100],\n",
       "        [ 0.1853, -0.0759],\n",
       "        [ 0.2452, -0.1073],\n",
       "        [ 0.2310, -0.1199],\n",
       "        [ 0.2469, -0.0658],\n",
       "        [ 0.1965, -0.0364],\n",
       "        [ 0.2462, -0.0177],\n",
       "        [ 0.3142, -0.0219],\n",
       "        [ 0.3590,  0.0357],\n",
       "        [ 0.3123,  0.0788],\n",
       "        [ 0.3214,  0.0519],\n",
       "        [ 0.3493,  0.0546],\n",
       "        [ 0.3466,  0.0208],\n",
       "        [ 0.3220,  0.0710],\n",
       "        [ 0.2525,  0.0653],\n",
       "        [ 0.2270,  0.1227],\n",
       "        [ 0.2028,  0.1348],\n",
       "        [ 0.1835,  0.0648],\n",
       "        [ 0.1822, -0.0224],\n",
       "        [ 0.1928, -0.0530],\n",
       "        [ 0.1934, -0.0228],\n",
       "        [ 0.2047,  0.0333],\n",
       "        [ 0.2029,  0.0352],\n",
       "        [ 0.2482,  0.0777],\n",
       "        [ 0.2713,  0.0535],\n",
       "        [ 0.3216,  0.0329],\n",
       "        [ 0.3410, -0.0136],\n",
       "        [ 0.3542,  0.0385],\n",
       "        [ 0.3587,  0.0870],\n",
       "        [ 0.3475,  0.1546],\n",
       "        [ 0.3102,  0.1724],\n",
       "        [ 0.2849,  0.1311],\n",
       "        [ 0.2769,  0.1092],\n",
       "        [ 0.2511,  0.0606],\n",
       "        [ 0.2748,  0.0477],\n",
       "        [ 0.2447,  0.0259],\n",
       "        [ 0.2130,  0.0832],\n",
       "        [ 0.1772,  0.1521],\n",
       "        [ 0.1452,  0.1129],\n",
       "        [ 0.1572,  0.0677],\n",
       "        [ 0.1724,  0.0180],\n",
       "        [ 0.1885, -0.0097],\n",
       "        [ 0.1936,  0.0046],\n",
       "        [ 0.2122,  0.0473],\n",
       "        [ 0.2448,  0.0677],\n",
       "        [ 0.2639,  0.0907],\n",
       "        [ 0.3026,  0.0525],\n",
       "        [ 0.3291,  0.0438],\n",
       "        [ 0.3536,  0.0134],\n",
       "        [ 0.3432,  0.0694],\n",
       "        [ 0.2713,  0.1410],\n",
       "        [ 0.2389,  0.1461],\n",
       "        [ 0.2231,  0.1527],\n",
       "        [ 0.1782,  0.0996],\n",
       "        [ 0.1944,  0.0568],\n",
       "        [ 0.2063,  0.0321],\n",
       "        [ 0.2256,  0.0259],\n",
       "        [ 0.2022,  0.0494],\n",
       "        [ 0.2301,  0.0546],\n",
       "        [ 0.2388,  0.0774],\n",
       "        [ 0.2762,  0.0516],\n",
       "        [ 0.3334,  0.0325],\n",
       "        [ 0.3591,  0.0132],\n",
       "        [ 0.4045,  0.0637],\n",
       "        [ 0.3937,  0.1304],\n",
       "        [ 0.3890,  0.1363],\n",
       "        [ 0.3614,  0.1663],\n",
       "        [ 0.3309,  0.1377],\n",
       "        [ 0.3158,  0.0953],\n",
       "        [ 0.2884,  0.0750],\n",
       "        [ 0.2528,  0.1186],\n",
       "        [ 0.2368,  0.1552],\n",
       "        [ 0.1869,  0.0800],\n",
       "        [ 0.2260,  0.0447],\n",
       "        [ 0.2372, -0.0470],\n",
       "        [ 0.2545, -0.0744],\n",
       "        [ 0.2709, -0.0246],\n",
       "        [ 0.2660,  0.0109],\n",
       "        [ 0.3228,  0.0627],\n",
       "        [ 0.3379, -0.0149],\n",
       "        [ 0.3934, -0.0089],\n",
       "        [ 0.3705,  0.0212],\n",
       "        [ 0.3363,  0.0807],\n",
       "        [ 0.3467,  0.1074],\n",
       "        [ 0.2932,  0.1220],\n",
       "        [ 0.2753,  0.0770],\n",
       "        [ 0.2783,  0.0744],\n",
       "        [ 0.2713,  0.0187],\n",
       "        [ 0.2235,  0.0072],\n",
       "        [ 0.2070,  0.0378],\n",
       "        [ 0.1612,  0.0263],\n",
       "        [ 0.1474,  0.0071],\n",
       "        [ 0.1732, -0.0089],\n",
       "        [ 0.2147, -0.0632],\n",
       "        [ 0.2490, -0.0994],\n",
       "        [ 0.2867, -0.0623],\n",
       "        [ 0.2706,  0.0060],\n",
       "        [ 0.2720,  0.0390],\n",
       "        [ 0.2935,  0.0760],\n",
       "        [ 0.2974,  0.0528],\n",
       "        [ 0.3095,  0.0201],\n",
       "        [ 0.2900,  0.0463],\n",
       "        [ 0.2133,  0.0307],\n",
       "        [ 0.1858, -0.0261],\n",
       "        [ 0.1844, -0.0219],\n",
       "        [ 0.2072,  0.0202],\n",
       "        [ 0.1668,  0.0345],\n",
       "        [ 0.1874,  0.0494],\n",
       "        [ 0.2356,  0.0260],\n",
       "        [ 0.2699, -0.0256],\n",
       "        [ 0.3207, -0.0032],\n",
       "        [ 0.3178, -0.0227],\n",
       "        [ 0.2768,  0.0424],\n",
       "        [ 0.2374,  0.1148],\n",
       "        [ 0.1728,  0.1390],\n",
       "        [ 0.1553,  0.1094],\n",
       "        [ 0.1430,  0.0931],\n",
       "        [ 0.1279,  0.0279],\n",
       "        [ 0.1618, -0.0192],\n",
       "        [ 0.2055, -0.0267],\n",
       "        [ 0.2353,  0.0473],\n",
       "        [ 0.2637,  0.0621],\n",
       "        [ 0.2621,  0.1160],\n",
       "        [ 0.2707,  0.1648],\n",
       "        [ 0.2774,  0.1485],\n",
       "        [ 0.3133,  0.1358],\n",
       "        [ 0.3251,  0.1239],\n",
       "        [ 0.3096,  0.1341],\n",
       "        [ 0.2637,  0.1734],\n",
       "        [ 0.2200,  0.2017],\n",
       "        [ 0.1560,  0.1678],\n",
       "        [ 0.1770,  0.1388],\n",
       "        [ 0.1936,  0.0826],\n",
       "        [ 0.2771,  0.0351],\n",
       "        [ 0.2643,  0.0313],\n",
       "        [ 0.2908,  0.0907],\n",
       "        [ 0.2824,  0.1161],\n",
       "        [ 0.2929,  0.1561],\n",
       "        [ 0.3236,  0.1554],\n",
       "        [ 0.3590,  0.1369],\n",
       "        [ 0.3698,  0.1004],\n",
       "        [ 0.3617,  0.1612],\n",
       "        [ 0.3228,  0.1988],\n",
       "        [ 0.2799,  0.2374],\n",
       "        [ 0.2548,  0.2474],\n",
       "        [ 0.2123,  0.1862],\n",
       "        [ 0.1894,  0.1419],\n",
       "        [ 0.2002,  0.0572],\n",
       "        [ 0.2034,  0.0798],\n",
       "        [ 0.1895,  0.1060],\n",
       "        [ 0.1766,  0.1216],\n",
       "        [ 0.1924,  0.1073],\n",
       "        [ 0.2035,  0.1128],\n",
       "        [ 0.2499,  0.0589],\n",
       "        [ 0.3182,  0.0181],\n",
       "        [ 0.3258,  0.0746],\n",
       "        [ 0.3228,  0.1204],\n",
       "        [ 0.3208,  0.2167],\n",
       "        [ 0.2770,  0.2424],\n",
       "        [ 0.2952,  0.2238],\n",
       "        [ 0.3137,  0.2035],\n",
       "        [ 0.3079,  0.1657],\n",
       "        [ 0.2741,  0.1609],\n",
       "        [ 0.2432,  0.1993],\n",
       "        [ 0.1761,  0.2356],\n",
       "        [ 0.1762,  0.2033],\n",
       "        [ 0.1618,  0.1407],\n",
       "        [ 0.2126,  0.0682],\n",
       "        [ 0.2110,  0.0769],\n",
       "        [ 0.2143,  0.1423],\n",
       "        [ 0.2415,  0.1590]], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c2e6062-5190-4eaf-b42b-dc7e831d9463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1667,  0.1133],\n",
       "        [ 0.1629,  0.1646],\n",
       "        [ 0.1853,  0.0999],\n",
       "        [ 0.1903,  0.0071],\n",
       "        [ 0.1867, -0.0271],\n",
       "        [ 0.1871, -0.0622],\n",
       "        [ 0.1952,  0.0053],\n",
       "        [ 0.1934,  0.0142],\n",
       "        [ 0.2327,  0.0144],\n",
       "        [ 0.2795, -0.0446],\n",
       "        [ 0.3267, -0.0318],\n",
       "        [ 0.3379,  0.0184],\n",
       "        [ 0.3160,  0.0715],\n",
       "        [ 0.3222,  0.1226],\n",
       "        [ 0.2836,  0.1478],\n",
       "        [ 0.2525,  0.1267],\n",
       "        [ 0.2680,  0.1042],\n",
       "        [ 0.2875,  0.0795],\n",
       "        [ 0.2761,  0.0395],\n",
       "        [ 0.2567,  0.0896],\n",
       "        [ 0.2302,  0.1378],\n",
       "        [ 0.1934,  0.1232],\n",
       "        [ 0.1918,  0.1362],\n",
       "        [ 0.2717,  0.1244],\n",
       "        [ 0.2945,  0.1343],\n",
       "        [ 0.3321,  0.0857],\n",
       "        [ 0.3889,  0.0531],\n",
       "        [ 0.3855,  0.0477],\n",
       "        [ 0.3849,  0.1393],\n",
       "        [ 0.3488,  0.1975],\n",
       "        [ 0.3079,  0.2048],\n",
       "        [ 0.2986,  0.1967],\n",
       "        [ 0.2780,  0.1252],\n",
       "        [ 0.2592,  0.0931],\n",
       "        [ 0.2363,  0.0373],\n",
       "        [ 0.2326,  0.0477],\n",
       "        [ 0.2445,  0.1145],\n",
       "        [ 0.2396,  0.1227],\n",
       "        [ 0.2459,  0.1319],\n",
       "        [ 0.2600,  0.1016],\n",
       "        [ 0.2935,  0.0887],\n",
       "        [ 0.2958,  0.0462],\n",
       "        [ 0.3202,  0.0798],\n",
       "        [ 0.2797,  0.1314],\n",
       "        [ 0.2703,  0.1635],\n",
       "        [ 0.2063,  0.1708],\n",
       "        [ 0.1618,  0.1560],\n",
       "        [ 0.1520,  0.1289],\n",
       "        [ 0.1700,  0.0609],\n",
       "        [ 0.1807,  0.0293],\n",
       "        [ 0.1949,  0.0130],\n",
       "        [ 0.2014,  0.0788],\n",
       "        [ 0.2263,  0.0750],\n",
       "        [ 0.2583,  0.0878],\n",
       "        [ 0.2828,  0.0938],\n",
       "        [ 0.3046,  0.0443],\n",
       "        [ 0.3574,  0.0444],\n",
       "        [ 0.3454,  0.0771],\n",
       "        [ 0.3426,  0.1330],\n",
       "        [ 0.3348,  0.1741],\n",
       "        [ 0.3118,  0.1879],\n",
       "        [ 0.2838,  0.1512],\n",
       "        [ 0.2978,  0.1360],\n",
       "        [ 0.2901,  0.0882],\n",
       "        [ 0.2846,  0.0797],\n",
       "        [ 0.2471,  0.1121],\n",
       "        [ 0.2008,  0.1077],\n",
       "        [ 0.2177,  0.0578],\n",
       "        [ 0.2632,  0.0390],\n",
       "        [ 0.3239,  0.0498],\n",
       "        [ 0.3408,  0.0645],\n",
       "        [ 0.3669,  0.0444],\n",
       "        [ 0.3699,  0.0055],\n",
       "        [ 0.3445,  0.0208],\n",
       "        [ 0.3355,  0.0703],\n",
       "        [ 0.3173,  0.1078],\n",
       "        [ 0.3032,  0.1300],\n",
       "        [ 0.2844,  0.0825],\n",
       "        [ 0.2836,  0.0421],\n",
       "        [ 0.2367,  0.0037],\n",
       "        [ 0.2257, -0.0329],\n",
       "        [ 0.2150, -0.0087],\n",
       "        [ 0.1856,  0.0166],\n",
       "        [ 0.1773,  0.0580],\n",
       "        [ 0.1624,  0.0290],\n",
       "        [ 0.1738, -0.0192],\n",
       "        [ 0.1823, -0.0229],\n",
       "        [ 0.2123, -0.0631],\n",
       "        [ 0.2358, -0.0829],\n",
       "        [ 0.2337, -0.0509],\n",
       "        [ 0.2060, -0.0227],\n",
       "        [ 0.2271, -0.0339],\n",
       "        [ 0.3245,  0.0219],\n",
       "        [ 0.3519,  0.0653],\n",
       "        [ 0.3015,  0.1079],\n",
       "        [ 0.3187,  0.0730],\n",
       "        [ 0.3187,  0.0526],\n",
       "        [ 0.3212,  0.0425],\n",
       "        [ 0.3086,  0.0704],\n",
       "        [ 0.2761,  0.0885],\n",
       "        [ 0.2150,  0.1052],\n",
       "        [ 0.1752,  0.1069],\n",
       "        [ 0.1854,  0.0815],\n",
       "        [ 0.1927,  0.0078],\n",
       "        [ 0.2201, -0.0169],\n",
       "        [ 0.2161,  0.0049],\n",
       "        [ 0.2034,  0.0082],\n",
       "        [ 0.2125,  0.0292],\n",
       "        [ 0.2162,  0.0856],\n",
       "        [ 0.2596,  0.0441],\n",
       "        [ 0.2825,  0.0402],\n",
       "        [ 0.3328,  0.0108],\n",
       "        [ 0.3419,  0.0514],\n",
       "        [ 0.3354,  0.1056],\n",
       "        [ 0.3164,  0.1663],\n",
       "        [ 0.2952,  0.2048],\n",
       "        [ 0.2923,  0.1758],\n",
       "        [ 0.2956,  0.1421],\n",
       "        [ 0.2666,  0.0994],\n",
       "        [ 0.2520,  0.0546],\n",
       "        [ 0.2141,  0.0435],\n",
       "        [ 0.2041,  0.1401],\n",
       "        [ 0.1784,  0.1214],\n",
       "        [ 0.1373,  0.1252],\n",
       "        [ 0.1392,  0.0377],\n",
       "        [ 0.1675,  0.0048],\n",
       "        [ 0.2175, -0.0459],\n",
       "        [ 0.1996, -0.0123],\n",
       "        [ 0.2066,  0.0530],\n",
       "        [ 0.2374,  0.0571],\n",
       "        [ 0.2574,  0.0909],\n",
       "        [ 0.2775,  0.0767],\n",
       "        [ 0.2900,  0.0617],\n",
       "        [ 0.3226,  0.0573],\n",
       "        [ 0.2991,  0.0743],\n",
       "        [ 0.2756,  0.1307],\n",
       "        [ 0.2417,  0.1905],\n",
       "        [ 0.2071,  0.1395],\n",
       "        [ 0.2079,  0.1436],\n",
       "        [ 0.2038,  0.0535],\n",
       "        [ 0.2296,  0.0341],\n",
       "        [ 0.2375,  0.0383],\n",
       "        [ 0.1923,  0.0645],\n",
       "        [ 0.2049,  0.0666],\n",
       "        [ 0.2355,  0.0899],\n",
       "        [ 0.2876,  0.0899],\n",
       "        [ 0.3218,  0.0605],\n",
       "        [ 0.3693,  0.0262],\n",
       "        [ 0.3867,  0.0476],\n",
       "        [ 0.3805,  0.1326],\n",
       "        [ 0.3615,  0.1738],\n",
       "        [ 0.3713,  0.1677],\n",
       "        [ 0.3553,  0.1126],\n",
       "        [ 0.3208,  0.0868],\n",
       "        [ 0.2945,  0.1004],\n",
       "        [ 0.2253,  0.1377],\n",
       "        [ 0.2135,  0.1492],\n",
       "        [ 0.1966,  0.0996],\n",
       "        [ 0.2169,  0.0328],\n",
       "        [ 0.2254, -0.0577],\n",
       "        [ 0.2484, -0.0233],\n",
       "        [ 0.2559, -0.0112],\n",
       "        [ 0.2940,  0.0570],\n",
       "        [ 0.3217,  0.0480],\n",
       "        [ 0.3331, -0.0100],\n",
       "        [ 0.3995, -0.0292],\n",
       "        [ 0.3838,  0.0022],\n",
       "        [ 0.3414,  0.0393],\n",
       "        [ 0.3192,  0.1018],\n",
       "        [ 0.2919,  0.1267],\n",
       "        [ 0.2848,  0.0875],\n",
       "        [ 0.2791,  0.0397],\n",
       "        [ 0.2583,  0.0015],\n",
       "        [ 0.2398,  0.0545],\n",
       "        [ 0.1991,  0.0261],\n",
       "        [ 0.1470,  0.0561],\n",
       "        [ 0.1297,  0.0509],\n",
       "        [ 0.1861, -0.0225],\n",
       "        [ 0.2199, -0.0528],\n",
       "        [ 0.2535, -0.0744],\n",
       "        [ 0.2690, -0.0633],\n",
       "        [ 0.2908,  0.0017],\n",
       "        [ 0.2934,  0.0421],\n",
       "        [ 0.2961,  0.0674],\n",
       "        [ 0.2770,  0.0668],\n",
       "        [ 0.3177,  0.0513],\n",
       "        [ 0.2761,  0.0370],\n",
       "        [ 0.2177,  0.0288],\n",
       "        [ 0.1956, -0.0374],\n",
       "        [ 0.2083, -0.0547],\n",
       "        [ 0.2210,  0.0059],\n",
       "        [ 0.2092,  0.0246],\n",
       "        [ 0.2267,  0.0331],\n",
       "        [ 0.2651,  0.0605],\n",
       "        [ 0.2945, -0.0010],\n",
       "        [ 0.3146, -0.0131],\n",
       "        [ 0.3056,  0.0321],\n",
       "        [ 0.2780,  0.0666],\n",
       "        [ 0.2392,  0.0932],\n",
       "        [ 0.2102,  0.1507],\n",
       "        [ 0.1520,  0.1366],\n",
       "        [ 0.1784,  0.0583],\n",
       "        [ 0.1614,  0.0150],\n",
       "        [ 0.1748, -0.0119],\n",
       "        [ 0.1727, -0.0626],\n",
       "        [ 0.2196, -0.0133],\n",
       "        [ 0.2617,  0.0855],\n",
       "        [ 0.2711,  0.1490],\n",
       "        [ 0.2861,  0.1988],\n",
       "        [ 0.2945,  0.1830],\n",
       "        [ 0.3045,  0.1444],\n",
       "        [ 0.3004,  0.1175],\n",
       "        [ 0.2736,  0.1799],\n",
       "        [ 0.2443,  0.2024],\n",
       "        [ 0.2020,  0.2057],\n",
       "        [ 0.1779,  0.1761],\n",
       "        [ 0.1882,  0.1268],\n",
       "        [ 0.2344,  0.0418],\n",
       "        [ 0.2200,  0.0393],\n",
       "        [ 0.2469,  0.0729],\n",
       "        [ 0.2605,  0.0723],\n",
       "        [ 0.2696,  0.1456],\n",
       "        [ 0.2928,  0.1648],\n",
       "        [ 0.3279,  0.1709],\n",
       "        [ 0.3506,  0.1052],\n",
       "        [ 0.3846,  0.1166],\n",
       "        [ 0.3551,  0.1476],\n",
       "        [ 0.3292,  0.1902],\n",
       "        [ 0.3067,  0.2326],\n",
       "        [ 0.2408,  0.2281],\n",
       "        [ 0.2329,  0.1705],\n",
       "        [ 0.2302,  0.1349],\n",
       "        [ 0.2177,  0.0854],\n",
       "        [ 0.1708,  0.0909],\n",
       "        [ 0.1980,  0.0790],\n",
       "        [ 0.1800,  0.1229],\n",
       "        [ 0.1639,  0.1026],\n",
       "        [ 0.2196,  0.0698],\n",
       "        [ 0.2647,  0.0628],\n",
       "        [ 0.2882,  0.0608],\n",
       "        [ 0.2936,  0.0740],\n",
       "        [ 0.3126,  0.1728],\n",
       "        [ 0.2989,  0.2112],\n",
       "        [ 0.3022,  0.1972],\n",
       "        [ 0.2989,  0.2179],\n",
       "        [ 0.2993,  0.1852],\n",
       "        [ 0.2980,  0.1598],\n",
       "        [ 0.2490,  0.1829],\n",
       "        [ 0.2309,  0.2037],\n",
       "        [ 0.1934,  0.2259],\n",
       "        [ 0.1468,  0.1711],\n",
       "        [ 0.1548,  0.1172],\n",
       "        [ 0.1815,  0.1024],\n",
       "        [ 0.1970,  0.0999],\n",
       "        [ 0.2118,  0.1301],\n",
       "        [ 0.2541,  0.1112]], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd046b8-d7a4-4257-b399-ffcec84fea2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459369b2-0618-439c-a58e-beff072946de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPart2(\n",
       "  (classifier): Linear(in_features=128, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5083b7a2-3cb6-42c7-9176-ab9680084e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to server at 172.16.19.7:1700\n",
      "Processed batch output: tensor([[[0.0801, 0.0803],\n",
      "         [0.0544, 0.0860],\n",
      "         [0.0579, 0.0831],\n",
      "         ...,\n",
      "         [0.0718, 0.0796],\n",
      "         [0.0763, 0.0774],\n",
      "         [0.0784, 0.0776]],\n",
      "\n",
      "        [[0.0794, 0.0728],\n",
      "         [0.0489, 0.0778],\n",
      "         [0.0517, 0.0765],\n",
      "         ...,\n",
      "         [0.0742, 0.0698],\n",
      "         [0.0789, 0.0696],\n",
      "         [0.0813, 0.0693]],\n",
      "\n",
      "        [[0.0620, 0.0875],\n",
      "         [0.0367, 0.0965],\n",
      "         [0.0408, 0.0900],\n",
      "         ...,\n",
      "         [0.0572, 0.0861],\n",
      "         [0.0617, 0.0840],\n",
      "         [0.0651, 0.0838]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0643, 0.0860],\n",
      "         [0.0432, 0.0895],\n",
      "         [0.0448, 0.0849],\n",
      "         ...,\n",
      "         [0.0592, 0.0837],\n",
      "         [0.0642, 0.0852],\n",
      "         [0.0684, 0.0826]],\n",
      "\n",
      "        [[0.0695, 0.0731],\n",
      "         [0.0478, 0.0839],\n",
      "         [0.0507, 0.0798],\n",
      "         ...,\n",
      "         [0.0683, 0.0706],\n",
      "         [0.0716, 0.0692],\n",
      "         [0.0740, 0.0714]],\n",
      "\n",
      "        [[0.0711, 0.0746],\n",
      "         [0.0450, 0.0836],\n",
      "         [0.0498, 0.0779],\n",
      "         ...,\n",
      "         [0.0675, 0.0735],\n",
      "         [0.0721, 0.0719],\n",
      "         [0.0746, 0.0726]]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "import pickle\n",
    "\n",
    "# Set up the client to connect to the server\n",
    "def start_client(server_host='172.16.19.7', server_port=1700):\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    client_socket.connect((server_host, server_port))\n",
    "    print(f\"Connected to server at {server_host}:{server_port}\")\n",
    "\n",
    "    return client_socket\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\", num_labels=2)\n",
    "\n",
    "# Manually split the model: Second half (classifier head)\n",
    "class BertPart2(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(BertPart2, self).__init__()\n",
    "        self.classifier = model.classifier  # Extract the classifier part of the model\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        return self.classifier(hidden_states)  # Pass the hidden states through the classifier\n",
    "\n",
    "# Create the second part of the model\n",
    "model_part2 = BertPart2(model)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_part2.to(device)\n",
    "\n",
    "# Start the client and connect to the server\n",
    "client_socket = start_client(server_host='172.16.19.7', server_port=1700)  # Change to your server's IP if needed\n",
    "\n",
    "# Continuously receive batches from the server and process\n",
    "while True:\n",
    "    try:\n",
    "        # Receive data from the server\n",
    "        received_data = b''\n",
    "        while True:\n",
    "            chunk = client_socket.recv(4096)\n",
    "            if not chunk:\n",
    "                break\n",
    "            received_data += chunk\n",
    "\n",
    "        if not received_data:\n",
    "            break  # Break if no more data is received\n",
    "\n",
    "        # Deserialize the received data\n",
    "        hidden_states = pickle.loads(received_data)\n",
    "\n",
    "        # Convert the received data to a torch tensor and move to device\n",
    "        hidden_states = torch.tensor(hidden_states).to(device)\n",
    "\n",
    "        # Forward pass through the second part of the model\n",
    "        outputs = model_part2(hidden_states)\n",
    "\n",
    "        # Perform any additional steps, like loss computation or inference\n",
    "        print(f\"Processed batch output: {outputs}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "        break\n",
    "\n",
    "# Close the connection when done\n",
    "client_socket.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69185abb-1533-4946-ba24-898f4d4d340c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertPart2(\n",
       "  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a615e426-7390-46ec-a392-7fbf9be9ba4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to server at 172.16.19.7:1700\n",
      "Processed hidden states output: tensor([[[ 1.8846e-02, -8.0754e-02],\n",
      "         [-9.3658e-02, -1.8274e-02],\n",
      "         [-1.5725e-01,  5.3438e-02],\n",
      "         [-1.8658e-01, -1.1773e-01],\n",
      "         [-1.6192e-01,  6.2647e-02],\n",
      "         [-7.8981e-02,  2.1435e-02],\n",
      "         [-1.2968e-01, -9.1606e-02],\n",
      "         [ 4.2567e-02, -1.3776e-01],\n",
      "         [ 4.9324e-02, -1.5062e-01],\n",
      "         [-6.5254e-02, -1.1223e-01],\n",
      "         [-8.0334e-02, -1.1276e-01],\n",
      "         [-8.6222e-02, -1.2212e-01],\n",
      "         [-8.3808e-02, -1.0657e-01],\n",
      "         [-1.1660e-01, -1.2760e-01],\n",
      "         [-1.0506e-01, -1.2915e-01],\n",
      "         [-9.4517e-02, -1.0409e-01],\n",
      "         [-1.2462e-01, -1.3303e-01],\n",
      "         [-1.1084e-01, -1.2664e-01],\n",
      "         [-9.7736e-02, -1.1102e-01],\n",
      "         [-8.6261e-02, -1.0912e-01],\n",
      "         [-5.7706e-02, -8.8994e-02],\n",
      "         [-6.1600e-02, -9.3611e-02],\n",
      "         [-6.2981e-02, -1.1349e-01],\n",
      "         [-6.0895e-02, -1.0948e-01],\n",
      "         [-8.7108e-02, -1.4991e-01],\n",
      "         [-9.0718e-02, -1.5544e-01],\n",
      "         [-8.4312e-02, -1.3510e-01],\n",
      "         [-1.2092e-01, -1.8022e-01],\n",
      "         [-1.1907e-01, -1.8325e-01],\n",
      "         [-1.0817e-01, -1.6890e-01],\n",
      "         [-8.8217e-02, -1.6888e-01],\n",
      "         [-5.6068e-02, -1.5876e-01],\n",
      "         [-4.9183e-02, -1.8592e-01],\n",
      "         [-8.6641e-03, -1.6513e-01],\n",
      "         [-5.6208e-03, -1.6979e-01],\n",
      "         [-2.6994e-02, -1.8316e-01],\n",
      "         [-2.1723e-02, -1.3517e-01],\n",
      "         [-4.0214e-02, -9.2038e-02],\n",
      "         [-7.2354e-02, -1.2288e-01],\n",
      "         [-8.4104e-02, -1.2058e-01],\n",
      "         [-9.4894e-02, -1.1839e-01],\n",
      "         [-9.8465e-02, -1.1833e-01],\n",
      "         [-9.5926e-02, -1.1147e-01],\n",
      "         [-1.1127e-01, -1.2063e-01],\n",
      "         [-1.0981e-01, -1.1658e-01],\n",
      "         [-8.5294e-02, -9.6698e-02],\n",
      "         [-8.9424e-02, -1.0563e-01],\n",
      "         [-5.6384e-02, -8.8600e-02],\n",
      "         [-5.6588e-02, -8.6670e-02],\n",
      "         [-7.0826e-02, -1.0926e-01],\n",
      "         [-7.7421e-02, -1.1411e-01],\n",
      "         [-8.8592e-02, -1.2607e-01],\n",
      "         [-9.2367e-02, -1.4092e-01],\n",
      "         [-9.8772e-02, -1.4593e-01],\n",
      "         [-1.0405e-01, -1.6127e-01],\n",
      "         [-9.5870e-02, -1.6219e-01],\n",
      "         [-1.0020e-01, -1.5069e-01],\n",
      "         [-1.1496e-01, -1.8516e-01],\n",
      "         [-1.0241e-01, -1.7967e-01],\n",
      "         [-4.4798e-02, -1.6380e-01],\n",
      "         [-1.9026e-02, -1.8733e-01],\n",
      "         [ 2.8707e-03, -1.5263e-01],\n",
      "         [-2.1100e-03, -1.2530e-01],\n",
      "         [-1.9847e-02, -1.1105e-01],\n",
      "         [-3.3232e-02, -8.6871e-02],\n",
      "         [-8.1563e-02, -1.2974e-01],\n",
      "         [-5.9643e-02, -1.1046e-01],\n",
      "         [-6.7578e-02, -9.8942e-02],\n",
      "         [-9.9532e-02, -1.2027e-01],\n",
      "         [-1.0447e-01, -1.1462e-01],\n",
      "         [-1.0757e-01, -1.1545e-01],\n",
      "         [-1.0839e-01, -1.1505e-01],\n",
      "         [-9.1314e-02, -1.0146e-01],\n",
      "         [-1.0200e-01, -1.0929e-01],\n",
      "         [-8.6187e-02, -9.9359e-02],\n",
      "         [-7.2491e-02, -8.9769e-02],\n",
      "         [-6.1744e-02, -9.2546e-02],\n",
      "         [-5.5156e-02, -8.6385e-02],\n",
      "         [-6.7558e-02, -1.0369e-01],\n",
      "         [-8.6201e-02, -1.4100e-01],\n",
      "         [-8.7532e-02, -1.2555e-01],\n",
      "         [-1.1554e-01, -1.5848e-01],\n",
      "         [-1.1659e-01, -1.6255e-01],\n",
      "         [-1.0330e-01, -1.5141e-01],\n",
      "         [-1.0950e-01, -1.6883e-01],\n",
      "         [-9.9965e-02, -1.4666e-01],\n",
      "         [-1.0192e-01, -1.7990e-01],\n",
      "         [-9.3149e-02, -1.8346e-01],\n",
      "         [-2.4035e-02, -1.5981e-01],\n",
      "         [-1.8656e-04, -1.8759e-01],\n",
      "         [ 1.0318e-02, -1.5420e-01],\n",
      "         [-4.3584e-03, -8.6426e-02],\n",
      "         [-2.3758e-02, -6.0868e-02],\n",
      "         [-5.9859e-02, -9.2239e-02],\n",
      "         [-5.4287e-02, -7.7914e-02],\n",
      "         [-7.1428e-02, -8.4735e-02],\n",
      "         [-8.4770e-02, -9.1455e-02],\n",
      "         [-7.3569e-02, -6.9382e-02],\n",
      "         [-9.4358e-02, -8.7375e-02],\n",
      "         [-9.5940e-02, -8.5778e-02],\n",
      "         [-8.5060e-02, -7.6717e-02],\n",
      "         [-8.4546e-02, -7.6285e-02],\n",
      "         [-7.8194e-02, -7.4976e-02],\n",
      "         [-6.3203e-02, -6.1471e-02],\n",
      "         [-7.0740e-02, -7.2308e-02],\n",
      "         [-4.8729e-02, -6.0398e-02],\n",
      "         [-4.4829e-02, -5.4457e-02],\n",
      "         [-7.6202e-02, -9.3875e-02],\n",
      "         [-8.4006e-02, -1.0271e-01],\n",
      "         [-9.5877e-02, -1.0820e-01],\n",
      "         [-9.9571e-02, -1.1706e-01],\n",
      "         [-7.6979e-02, -8.5968e-02],\n",
      "         [-1.0982e-01, -1.2632e-01],\n",
      "         [-1.2222e-01, -1.5467e-01],\n",
      "         [-9.8302e-02, -1.4476e-01],\n",
      "         [-8.9944e-02, -1.6245e-01],\n",
      "         [-3.4978e-02, -1.2267e-01],\n",
      "         [-1.0842e-02, -8.5404e-02],\n",
      "         [-9.4748e-03, -1.0958e-01],\n",
      "         [-1.3399e-02, -7.9117e-02],\n",
      "         [-2.5843e-02, -5.9712e-02],\n",
      "         [-4.3254e-02, -6.1434e-02],\n",
      "         [-4.3442e-02, -5.2076e-02],\n",
      "         [-7.5639e-02, -7.4964e-02],\n",
      "         [-9.2335e-02, -7.6415e-02],\n",
      "         [-9.3018e-02, -5.9477e-02],\n",
      "         [-1.0690e-01, -5.8383e-02],\n",
      "         [-9.8873e-02, -4.4526e-02]],\n",
      "\n",
      "        [[ 7.4828e-02, -5.6329e-02],\n",
      "         [ 1.5775e-01, -1.4357e-02],\n",
      "         [ 1.6146e-01,  1.1428e-01],\n",
      "         [ 1.4511e-01,  3.5820e-02],\n",
      "         [ 1.1847e-01,  5.6985e-02],\n",
      "         [ 1.9460e-01, -1.3311e-01],\n",
      "         [ 1.2951e-01,  2.3256e-02],\n",
      "         [ 5.6347e-02, -1.1791e-01],\n",
      "         [ 2.6202e-02, -1.6847e-01],\n",
      "         [-1.9415e-02, -1.0171e-01],\n",
      "         [-4.2523e-02, -1.0287e-01],\n",
      "         [-4.9380e-02, -1.1103e-01],\n",
      "         [-3.3702e-02, -8.8261e-02],\n",
      "         [-4.3001e-02, -8.1464e-02],\n",
      "         [-5.3295e-02, -8.7868e-02],\n",
      "         [-2.9354e-02, -6.7871e-02],\n",
      "         [-2.4643e-02, -5.1204e-02],\n",
      "         [-2.0957e-02, -5.6886e-02],\n",
      "         [-2.0865e-02, -5.3465e-02],\n",
      "         [-3.7649e-02, -9.0053e-02],\n",
      "         [-5.8673e-03, -7.9243e-02],\n",
      "         [-2.2676e-02, -7.0918e-02],\n",
      "         [-2.0193e-02, -9.5961e-02],\n",
      "         [-1.6566e-02, -7.6669e-02],\n",
      "         [-3.5748e-02, -1.1531e-01],\n",
      "         [-2.8265e-02, -1.1581e-01],\n",
      "         [ 1.5030e-02, -9.0672e-02],\n",
      "         [ 5.1280e-02, -8.8684e-02],\n",
      "         [ 5.6268e-02, -1.0614e-01],\n",
      "         [ 7.5090e-02, -1.1950e-01],\n",
      "         [ 9.1153e-02, -1.1699e-01],\n",
      "         [ 1.2093e-01, -1.4341e-01],\n",
      "         [ 1.2122e-01, -1.2135e-01],\n",
      "         [ 1.1289e-01, -1.5652e-01],\n",
      "         [ 1.0597e-01, -1.6810e-01],\n",
      "         [ 2.4663e-02, -1.7273e-01],\n",
      "         [ 2.5256e-02, -1.3646e-01],\n",
      "         [-1.0693e-02, -9.2380e-02],\n",
      "         [-3.6900e-02, -1.2523e-01],\n",
      "         [-5.0382e-02, -1.2078e-01],\n",
      "         [-5.9668e-02, -1.1835e-01],\n",
      "         [-6.0771e-02, -1.1470e-01],\n",
      "         [-4.8137e-02, -1.0058e-01],\n",
      "         [-5.0551e-02, -1.0057e-01],\n",
      "         [-4.5542e-02, -9.6083e-02],\n",
      "         [-4.1261e-02, -9.8640e-02],\n",
      "         [-4.4110e-02, -1.0844e-01],\n",
      "         [-1.6769e-02, -9.2085e-02],\n",
      "         [-2.3704e-02, -8.2114e-02],\n",
      "         [-3.5213e-02, -1.1411e-01],\n",
      "         [-4.0630e-02, -1.1518e-01],\n",
      "         [-4.7120e-02, -1.2152e-01],\n",
      "         [-3.9654e-02, -1.2632e-01],\n",
      "         [-2.1663e-02, -1.1219e-01],\n",
      "         [-1.1015e-02, -1.2256e-01],\n",
      "         [ 2.4286e-03, -1.1781e-01],\n",
      "         [ 5.9058e-02, -8.5772e-02],\n",
      "         [ 9.8454e-02, -7.6077e-02],\n",
      "         [ 1.2947e-01, -8.3596e-02],\n",
      "         [ 1.6633e-01, -1.4626e-01],\n",
      "         [ 1.4415e-01, -1.8047e-01],\n",
      "         [ 1.3338e-01, -1.4885e-01],\n",
      "         [ 4.7592e-02, -9.8213e-02],\n",
      "         [ 2.2005e-02, -1.0604e-01],\n",
      "         [-4.1549e-03, -8.9658e-02],\n",
      "         [-4.0334e-02, -1.3001e-01],\n",
      "         [-2.5137e-02, -1.1471e-01],\n",
      "         [-3.5454e-02, -9.8929e-02],\n",
      "         [-5.5894e-02, -1.1903e-01],\n",
      "         [-5.8339e-02, -1.1123e-01],\n",
      "         [-5.9028e-02, -1.1163e-01],\n",
      "         [-5.0912e-02, -1.0749e-01],\n",
      "         [-3.3670e-02, -8.4953e-02],\n",
      "         [-3.8997e-02, -1.0046e-01],\n",
      "         [-3.7128e-02, -1.0456e-01],\n",
      "         [-2.9723e-02, -9.2144e-02],\n",
      "         [-2.0235e-02, -9.6431e-02],\n",
      "         [-2.2704e-02, -8.0866e-02],\n",
      "         [-2.8551e-02, -9.8502e-02],\n",
      "         [-3.6870e-02, -1.2977e-01],\n",
      "         [-2.2734e-02, -1.1147e-01],\n",
      "         [-8.0189e-03, -1.0872e-01],\n",
      "         [ 1.1698e-02, -1.1195e-01],\n",
      "         [-1.0892e-02, -1.1938e-01],\n",
      "         [ 5.1521e-03, -1.1627e-01],\n",
      "         [ 5.5311e-02, -8.3882e-02],\n",
      "         [ 1.0249e-01, -7.0992e-02],\n",
      "         [ 1.2312e-01, -8.2937e-02],\n",
      "         [ 1.6817e-01, -1.5942e-01],\n",
      "         [ 1.3666e-01, -1.6685e-01],\n",
      "         [ 1.2635e-01, -1.4285e-01],\n",
      "         [ 2.6153e-02, -7.6282e-02],\n",
      "         [-1.9198e-03, -6.0711e-02],\n",
      "         [-3.1557e-02, -9.4831e-02],\n",
      "         [-3.2004e-02, -7.7988e-02],\n",
      "         [-4.6898e-02, -8.3880e-02],\n",
      "         [-5.4477e-02, -8.9350e-02],\n",
      "         [-4.6152e-02, -6.2412e-02],\n",
      "         [-6.0315e-02, -8.3693e-02],\n",
      "         [-5.9612e-02, -8.1519e-02],\n",
      "         [-4.7934e-02, -7.2056e-02],\n",
      "         [-4.3951e-02, -7.3846e-02],\n",
      "         [-3.4905e-02, -7.0633e-02],\n",
      "         [-3.2969e-02, -6.2779e-02],\n",
      "         [-3.9171e-02, -7.6020e-02],\n",
      "         [-2.7160e-02, -5.7272e-02],\n",
      "         [-2.9606e-02, -4.3885e-02],\n",
      "         [-4.5279e-02, -9.3185e-02],\n",
      "         [-4.9974e-02, -1.0008e-01],\n",
      "         [-5.9628e-02, -1.0243e-01],\n",
      "         [-5.6844e-02, -1.0636e-01],\n",
      "         [-3.1646e-02, -6.1104e-02],\n",
      "         [-2.6506e-02, -8.3617e-02],\n",
      "         [ 2.2686e-02, -8.0038e-02],\n",
      "         [ 1.9602e-02, -9.8539e-02],\n",
      "         [ 4.8462e-02, -1.1051e-01],\n",
      "         [ 6.5759e-02, -9.0408e-02],\n",
      "         [ 3.5909e-02, -5.3206e-02],\n",
      "         [ 4.8460e-02, -9.0802e-02],\n",
      "         [ 1.8098e-02, -6.4713e-02],\n",
      "         [-6.5250e-03, -4.9284e-02],\n",
      "         [-2.3880e-02, -5.7835e-02],\n",
      "         [-2.5999e-02, -4.8988e-02],\n",
      "         [-5.2977e-02, -7.5010e-02],\n",
      "         [-6.7563e-02, -7.7698e-02],\n",
      "         [-6.7834e-02, -5.7195e-02],\n",
      "         [-7.6133e-02, -5.1483e-02],\n",
      "         [-6.8814e-02, -4.2000e-02]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Processed pooled output: tensor([[0.0022, 0.0011],\n",
      "        [0.0073, 0.0062]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification\n",
    "import pickle\n",
    "\n",
    "# Set up the client to connect to the server\n",
    "def start_client(server_host='127.0.0.1', server_port=1700):\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    client_socket.connect((server_host, server_port))\n",
    "    print(f\"Connected to server at {server_host}:{server_port}\")\n",
    "\n",
    "    return client_socket\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\", num_labels=2)\n",
    "\n",
    "# Manually split the model: Classifier head\n",
    "class BertPart2(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(BertPart2, self).__init__()\n",
    "        self.classifier = model.classifier  # Extract the classifier part of the model\n",
    "\n",
    "    def forward(self, hidden_states, pooled_output):\n",
    "        # You can perform operations on hidden_states and pooled_output here.\n",
    "        return self.classifier(hidden_states), self.classifier(pooled_output)\n",
    "\n",
    "# Create the second part of the model\n",
    "model_part2 = BertPart2(model)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_part2.to(device)\n",
    "\n",
    "# Start the client and connect to the server\n",
    "client_socket = start_client(server_host='172.16.19.7', server_port=1700)  # Change to your server's IP if needed\n",
    "\n",
    "# Continuously receive batches from the server and process\n",
    "while True:\n",
    "    try:\n",
    "        # Receive data from the server\n",
    "        received_data = b''\n",
    "        while True:\n",
    "            chunk = client_socket.recv(4096)\n",
    "            if not chunk:\n",
    "                break\n",
    "            received_data += chunk\n",
    "\n",
    "        if not received_data:\n",
    "            break  # Break if no more data is received\n",
    "\n",
    "        # Deserialize the received data\n",
    "        data = pickle.loads(received_data)\n",
    "        hidden_states = torch.tensor(data['hidden_states']).to(device)\n",
    "        pooled_output = torch.tensor(data['pooled_output']).to(device)\n",
    "\n",
    "        # Forward pass through the second part of the model\n",
    "        outputs_hidden, outputs_pooled = model_part2(hidden_states, pooled_output)\n",
    "\n",
    "        # Perform any additional steps, like loss computation or inference\n",
    "        print(f\"Processed hidden states output: {outputs_hidden}\")\n",
    "        print(f\"Processed pooled output: {outputs_pooled}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "        break\n",
    "\n",
    "# Close the connection when done\n",
    "client_socket.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6173e9b-9012-40a1-b1ec-3388cfd20a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4834e-02, -5.3914e-02, -1.8894e-02,  1.9982e-02, -1.3638e-02,\n",
       "          1.2368e-02, -5.0215e-02,  1.9935e-02, -1.0283e-02, -5.8028e-02,\n",
       "         -3.5619e-02,  5.6508e-03,  2.0197e-02, -4.6270e-02,  2.5706e-02,\n",
       "          7.7902e-03, -1.4050e-02,  1.0448e-02,  3.9982e-03,  1.1972e-02,\n",
       "          1.6616e-02, -2.0609e-03,  3.5185e-02, -2.0689e-02, -2.4612e-02,\n",
       "         -3.1404e-02, -2.0241e-03,  3.8373e-02,  2.8636e-03, -2.1974e-02,\n",
       "          1.3790e-03, -3.2166e-02, -4.3881e-02, -6.6052e-02, -4.0423e-04,\n",
       "         -2.4887e-02, -2.8885e-02, -6.6117e-02, -2.7433e-02, -1.8742e-02,\n",
       "         -4.6978e-03, -2.0703e-02, -4.8427e-03,  7.6686e-02,  1.1949e-02,\n",
       "         -3.2272e-02,  9.4810e-03, -2.5523e-02, -1.9180e-02,  2.0887e-03,\n",
       "         -9.4648e-02, -4.3184e-02,  2.1908e-02, -1.6801e-02, -1.5450e-02,\n",
       "         -1.5052e-02, -4.8178e-02, -8.6782e-03,  3.8474e-04, -2.3081e-02,\n",
       "          7.3196e-03, -2.8303e-02,  1.4755e-02,  8.6737e-03, -3.7712e-02,\n",
       "         -2.6995e-02, -7.4640e-02,  2.9433e-03,  6.3980e-03,  1.2206e-02,\n",
       "         -2.5362e-02,  6.8793e-03, -2.3256e-02, -1.1177e-02, -9.5143e-03,\n",
       "          4.5886e-02,  6.2567e-02, -1.1562e-02, -7.3594e-03,  9.0836e-03,\n",
       "          1.0284e-01,  1.9853e-02, -2.8630e-02, -6.7527e-02, -3.0387e-02,\n",
       "          2.9396e-02, -3.4288e-02,  9.4374e-03, -5.0397e-02, -1.9266e-02,\n",
       "         -1.7459e-02,  5.9869e-02,  3.7876e-02, -2.7855e-02,  3.6418e-02,\n",
       "         -7.2077e-02, -1.5954e-03, -1.0871e-02, -2.1460e-02,  3.5966e-03,\n",
       "          2.4981e-02, -2.5574e-02,  2.8362e-02,  2.9593e-03, -1.1396e-02,\n",
       "          3.6209e-03,  4.5454e-02, -4.5542e-02,  2.8552e-02,  7.2202e-02,\n",
       "          1.2796e-04,  1.2695e-02, -8.1028e-03, -1.8392e-02,  2.1331e-02,\n",
       "         -3.8465e-02, -2.2292e-03,  9.6907e-03, -2.3018e-02, -8.2009e-02,\n",
       "          8.8792e-03,  6.6048e-02,  2.2590e-02, -1.5330e-02,  2.4297e-02,\n",
       "          5.1835e-02,  3.2187e-02, -3.2090e-02,  3.3500e-02,  1.3292e-02,\n",
       "          3.1963e-03, -5.2344e-03,  6.9710e-03,  2.7159e-02,  5.1871e-02,\n",
       "         -1.4191e-02,  1.1432e-02,  2.7764e-02, -3.4789e-02,  2.8105e-02,\n",
       "          2.3747e-02, -3.7255e-02,  2.1980e-02, -1.7183e-02,  1.7914e-02,\n",
       "          2.1688e-02, -3.7327e-02,  4.2712e-02, -1.3981e-02, -1.0445e-02,\n",
       "          2.7197e-02,  2.2320e-02,  3.3484e-02,  1.3310e-02,  3.3014e-02,\n",
       "          1.5329e-03,  3.9773e-02, -3.5236e-02,  4.2697e-02,  3.9663e-02,\n",
       "         -3.1908e-02,  1.9188e-02, -5.3612e-02,  1.7477e-02, -3.4508e-03,\n",
       "          4.8339e-03,  1.7406e-02,  3.8315e-02,  4.5818e-02, -1.9847e-02,\n",
       "         -8.2904e-02, -1.3124e-02, -4.0355e-02, -3.0648e-02, -2.2436e-02,\n",
       "         -1.7803e-02, -2.1921e-02,  3.6515e-02, -2.6520e-02,  2.7587e-02,\n",
       "          3.2132e-02,  2.0384e-02, -1.7610e-02,  3.0515e-03,  7.6397e-03,\n",
       "         -6.8892e-03, -1.6524e-02,  2.6146e-03,  4.0292e-02,  2.0976e-02,\n",
       "          1.6914e-02,  8.6246e-03, -1.1756e-02,  1.5322e-02,  1.7766e-02,\n",
       "         -7.0211e-02,  1.1098e-02, -7.3401e-04,  4.4348e-02,  6.2029e-02,\n",
       "          1.0865e-02, -8.5801e-03,  1.6393e-02, -4.9111e-02, -3.3126e-02,\n",
       "          3.6524e-02,  3.3275e-02, -1.4420e-02,  1.5752e-02, -4.6966e-02,\n",
       "         -1.5204e-02, -4.2016e-02,  2.9898e-02,  1.0339e-02, -4.0012e-02,\n",
       "          1.9407e-02, -1.7455e-02,  4.5439e-02, -2.9537e-02,  1.7830e-02,\n",
       "          2.0780e-02,  2.0357e-02, -1.0439e-02,  1.5193e-02,  2.5587e-02,\n",
       "         -1.9213e-02,  6.5641e-03,  2.2705e-02, -1.1397e-02, -6.8392e-02,\n",
       "          1.3541e-02, -2.3130e-03, -2.8520e-02,  3.1321e-02,  2.6016e-02,\n",
       "         -8.3808e-03,  1.4690e-04,  1.3248e-02, -2.9909e-03,  1.5922e-02,\n",
       "         -3.2377e-02, -7.0315e-02,  4.4359e-03,  3.0133e-02, -8.6873e-03,\n",
       "         -2.0551e-02,  4.0146e-04,  4.1597e-03, -2.7728e-02, -2.9491e-03,\n",
       "          5.7514e-02, -3.0251e-02,  2.6962e-03, -3.7654e-02, -2.9324e-02,\n",
       "         -3.0027e-02,  1.4940e-02,  1.7955e-02,  2.9596e-02, -3.1074e-02,\n",
       "         -2.7326e-02, -1.0237e-03, -1.0854e-01,  9.5713e-03,  1.6612e-02,\n",
       "          2.6606e-02,  2.9285e-02, -2.5119e-02, -2.3186e-02,  3.1301e-02,\n",
       "          1.0279e-02, -9.2222e-03, -1.0425e-02,  3.6598e-04,  5.6008e-03,\n",
       "         -2.4193e-02,  4.0018e-02,  2.4825e-03, -1.8696e-02, -6.7832e-02,\n",
       "          3.0490e-02, -4.0618e-02, -3.5328e-02, -1.0420e-02, -6.1410e-02,\n",
       "         -8.2597e-03,  5.1639e-02, -3.7552e-02,  4.7118e-02,  1.3113e-02,\n",
       "         -4.2956e-04,  4.0001e-02,  7.3734e-02, -1.1583e-02,  2.0482e-02,\n",
       "         -2.3023e-02,  3.2546e-04, -1.1420e-02, -2.3186e-02, -2.3652e-03,\n",
       "          3.9059e-03, -4.6512e-02, -2.7778e-02, -2.6234e-02, -7.4500e-03,\n",
       "          1.1349e-02,  2.8015e-02,  3.3960e-03,  6.3584e-02, -1.4756e-03,\n",
       "         -2.2327e-02,  5.1301e-02],\n",
       "        [-1.3437e-02, -2.7778e-02, -1.7249e-02,  2.7519e-02, -4.2318e-03,\n",
       "          8.1666e-03, -4.8227e-02,  2.6288e-02,  2.0547e-02, -6.7253e-02,\n",
       "         -4.4827e-02,  2.8150e-02,  2.7181e-02, -4.7479e-02,  2.9899e-02,\n",
       "          1.7185e-02, -1.1812e-02,  3.1070e-02,  7.5594e-03,  2.0115e-02,\n",
       "          1.2019e-02, -1.1213e-02,  4.5062e-02, -1.0537e-02, -2.6275e-02,\n",
       "         -2.6207e-02, -1.3208e-03,  4.0994e-02,  1.9940e-02, -2.0179e-02,\n",
       "          1.4334e-02, -2.6796e-02, -3.7262e-02, -6.0899e-02, -7.0887e-03,\n",
       "         -2.0749e-02, -2.4687e-02, -6.6060e-02, -2.4195e-02, -2.2872e-02,\n",
       "          1.9201e-02, -2.5245e-02,  9.0623e-04,  7.9518e-02,  9.8649e-03,\n",
       "         -4.2490e-02,  2.6405e-02, -2.6171e-02, -3.1291e-02,  1.5682e-02,\n",
       "         -9.1381e-02, -5.3435e-02,  1.8166e-02, -2.3308e-02, -2.9618e-02,\n",
       "         -4.5095e-03, -4.6758e-02, -1.3670e-03, -5.0843e-03, -1.1460e-02,\n",
       "          8.6281e-04, -3.3718e-02,  1.8699e-02,  1.2107e-02, -2.6658e-02,\n",
       "         -2.5188e-02, -6.4374e-02,  3.8363e-03,  9.1011e-03,  1.9718e-02,\n",
       "         -3.5210e-02,  8.6890e-03, -2.1380e-02, -1.8085e-02, -2.5042e-02,\n",
       "          4.6789e-02,  5.6577e-02, -1.9059e-02, -1.9228e-02,  1.6804e-02,\n",
       "          1.0717e-01,  4.0449e-02, -2.4351e-02, -6.8881e-02, -3.3849e-02,\n",
       "          2.8364e-02, -3.7423e-02,  7.7498e-03, -6.4857e-02, -8.7353e-03,\n",
       "         -1.1754e-02,  5.4752e-02,  4.1647e-02, -2.5121e-02,  3.1459e-02,\n",
       "         -6.7453e-02,  2.4052e-03, -6.0301e-03, -1.4881e-02, -8.5008e-03,\n",
       "          8.0524e-03, -2.4644e-02,  2.0931e-02, -2.1369e-03,  4.2663e-03,\n",
       "          4.9987e-03,  4.1568e-02, -4.6818e-02,  1.7238e-02,  8.3542e-02,\n",
       "          1.1641e-02, -9.9016e-05, -2.1649e-03, -1.7564e-02,  2.3549e-02,\n",
       "         -4.8334e-02,  2.8865e-03, -2.5334e-03, -1.8511e-02, -7.8653e-02,\n",
       "          3.2991e-02,  7.6610e-02,  3.3990e-02, -1.3330e-02,  1.7717e-02,\n",
       "          3.9312e-02,  2.9857e-02, -3.6100e-02,  2.1734e-02,  9.3105e-03,\n",
       "         -3.9416e-03, -7.5984e-03,  1.3083e-02,  3.5430e-02,  4.2257e-02,\n",
       "         -1.3639e-02,  2.8392e-03,  2.1501e-02, -3.1760e-02,  2.6294e-02,\n",
       "          2.1399e-02, -4.0925e-02,  2.1777e-02, -2.4254e-02,  1.5745e-02,\n",
       "          1.8023e-02, -4.0223e-02,  4.8970e-02, -2.8984e-02, -1.1817e-02,\n",
       "          3.7563e-02,  3.6505e-02,  2.2276e-02,  1.2854e-02,  5.4634e-02,\n",
       "         -1.8428e-03,  3.4082e-02, -4.1080e-02,  4.3678e-02,  3.8423e-02,\n",
       "         -2.7904e-02,  1.2250e-02, -5.5351e-02,  1.2627e-02,  6.7305e-03,\n",
       "          8.2111e-04,  1.1394e-02,  3.5746e-02,  4.3515e-02, -3.4206e-02,\n",
       "         -7.0912e-02,  2.0594e-03, -3.3569e-02, -2.6271e-02, -1.7083e-02,\n",
       "         -2.4029e-02, -7.4311e-03,  3.0662e-02, -2.6236e-02,  2.2927e-02,\n",
       "          3.6120e-02,  2.6938e-02, -8.1592e-03, -4.7408e-03,  3.4917e-05,\n",
       "          1.1192e-03, -1.0483e-03,  4.3862e-03,  4.4943e-02,  2.7318e-02,\n",
       "          2.2500e-02,  8.9508e-03, -1.4608e-02,  1.8384e-02,  1.0919e-02,\n",
       "         -8.2897e-02,  1.0682e-02,  3.6907e-03,  4.8711e-02,  6.7273e-02,\n",
       "          2.9180e-03,  6.7566e-03,  2.5626e-02, -6.2997e-02, -3.7654e-02,\n",
       "          4.0901e-02,  4.3587e-02, -9.4036e-03,  1.3298e-02, -3.7045e-02,\n",
       "         -7.6815e-03, -2.7236e-02,  1.5361e-02, -3.6686e-03, -4.2741e-02,\n",
       "          1.4892e-02, -1.1683e-02,  3.1150e-02, -2.2612e-02,  1.0121e-02,\n",
       "         -5.1250e-03,  1.6337e-02, -9.1920e-03, -1.0504e-03,  1.5260e-02,\n",
       "         -3.8135e-02,  8.1093e-03,  1.6056e-02, -1.6455e-02, -7.2379e-02,\n",
       "          4.9254e-03, -7.3552e-03, -3.1145e-02,  1.7170e-02,  9.0732e-03,\n",
       "          4.3381e-03, -6.2870e-03,  1.9801e-02, -7.1540e-03,  4.0828e-03,\n",
       "         -2.7337e-02, -7.0623e-02, -3.3111e-03,  2.3927e-02, -1.1860e-02,\n",
       "         -1.1586e-02,  4.5223e-03,  9.6349e-03, -3.1339e-02, -1.2624e-02,\n",
       "          6.2899e-02, -2.1638e-02,  7.5381e-03, -3.3942e-02, -4.4722e-02,\n",
       "         -2.3022e-02,  2.2354e-02,  2.5221e-02,  2.5612e-02, -2.4068e-02,\n",
       "         -3.0491e-02, -6.1304e-03, -1.0352e-01,  1.3656e-02,  1.5657e-02,\n",
       "          3.7253e-02,  2.8521e-02, -1.0947e-02, -8.4100e-03,  1.6523e-02,\n",
       "          3.3941e-03, -3.1418e-02,  1.9651e-03, -8.0566e-03, -9.2125e-03,\n",
       "         -6.1009e-03,  3.9114e-02, -7.7644e-04, -2.7599e-02, -7.0548e-02,\n",
       "          2.2860e-02, -5.9477e-02, -3.4022e-02, -1.1135e-02, -5.3731e-02,\n",
       "         -3.4805e-03,  5.1474e-02, -5.1290e-02,  4.2518e-02,  2.8570e-03,\n",
       "          1.7147e-03,  4.7010e-02,  7.5502e-02, -1.1890e-02,  2.1110e-02,\n",
       "         -9.3172e-03,  2.1597e-02, -2.9139e-02, -4.3180e-02, -2.0535e-02,\n",
       "          7.1603e-03, -3.7856e-02, -2.7888e-02, -3.0411e-02, -7.4845e-03,\n",
       "          2.0172e-02,  3.9930e-02,  4.5981e-03,  6.9289e-02, -1.9262e-02,\n",
       "         -1.4334e-02,  6.2371e-02]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf5e35-46ec-46b3-9e90-547f721e7d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to server at 172.16.19.7:1700\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import pickle\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Custom Dataset for IMDb\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, tokenizer, split):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = load_dataset('imdb', split=split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            item['text'],\n",
    "            add_special_tokens=True,\n",
    "            max_length=128,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        label = 1 if item['label'] == 'pos' else 0\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Set up the client to connect to the server\n",
    "def start_client(server_host='127.0.0.1', server_port=1700):\n",
    "    client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    client_socket.connect((server_host, server_port))\n",
    "    print(f\"Connected to server at {server_host}:{server_port}\")\n",
    "\n",
    "    return client_socket\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\", num_labels=2)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Start the client and connect to the server\n",
    "client_socket = start_client(server_host='172.16.19.7', server_port=1700)  # Change to your server's IP if needed\n",
    "\n",
    "# Create a DataLoader for the IMDb test dataset\n",
    "tokenizer = BertTokenizer.from_pretrained(\"huawei-noah/TinyBERT_General_4L_312D\")\n",
    "test_dataset = IMDBDataset(tokenizer, split='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "# Continuously receive batches from the server and process\n",
    "for batch in test_loader:\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    true_labels = batch['label'].cpu().numpy()  # Collect true labels for accuracy calculation\n",
    "    labels.extend(true_labels)\n",
    "\n",
    "    try:\n",
    "        # Receive data from the server\n",
    "        received_data = b''\n",
    "        while True:\n",
    "            chunk = client_socket.recv(4096)\n",
    "            if not chunk:\n",
    "                break\n",
    "            received_data += chunk\n",
    "\n",
    "        if not received_data:\n",
    "            break  # Break if no more data is received\n",
    "\n",
    "        # Deserialize the received data\n",
    "        hidden_states = pickle.loads(received_data)\n",
    "\n",
    "        # Convert the received data to a torch tensor and move to device\n",
    "        hidden_states = torch.tensor(hidden_states).to(device)\n",
    "\n",
    "        # Forward pass through the pooling and classifier head\n",
    "        outputs = model(hidden_states)\n",
    "\n",
    "        # Get predictions\n",
    "        logits = outputs.logits\n",
    "        predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during processing: {e}\")\n",
    "        break\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Close the connection when done\n",
    "client_socket.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887783c-1dad-4283-a544-90849c05fa17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
